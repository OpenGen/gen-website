<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS --> 
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z" crossorigin="anonymous">
    <link rel="stylesheet" href="/assets/css/styles.css">

    <!-- MathJax -->
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <title>Data-Driven Proposals in Gen</title>
  </head>
  <body>
    
    <header class="navbar navbar-expand navbar-dark flex-column flex-md-row bd-navbar">
  <a class="navbar-brand mr-0 mr-md-2" href="/" aria-label="Gen">
<svg version="1.1" width="36" height="36" viewBox="0.0 0.0 433.7244094488189 432.76640419947506" fill="none" stroke="none" stroke-linecap="square" stroke-miterlimit="10" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg"><clipPath id="p.0"><path d="m0 0l433.7244 0l0 432.76642l-433.7244 0l0 -432.76642z" clip-rule="nonzero"/></clipPath><g clip-path="url(#p.0)"><path fill="#000000" fill-opacity="0.0" d="m0 0l433.7244 0l0 432.76642l-433.7244 0z" fill-rule="evenodd"/><path fill="#000000" fill-opacity="0.0" d="m526.3617 215.97453l0 0c0 -112.37038 91.09418 -203.46457 203.4646 -203.46457l0 0c53.96216 0 105.71411 21.436382 143.87115 59.593395c38.156982 38.157005 59.593384 89.90901 59.593384 143.87117l0 0c0 112.37038 -91.09418 203.46455 -203.46454 203.46455l0 0c-112.37042 0 -203.4646 -91.09418 -203.4646 -203.46455z" fill-rule="evenodd"/><path stroke="#ffffff" stroke-width="16.0" stroke-linejoin="round" stroke-linecap="butt" d="m526.3617 215.97453l0 0c0 -112.37038 91.09418 -203.46457 203.4646 -203.46457l0 0c53.96216 0 105.71411 21.436382 143.87115 59.593395c38.156982 38.157005 59.593384 89.90901 59.593384 143.87117l0 0c0 112.37038 -91.09418 203.46455 -203.46454 203.46455l0 0c-112.37042 0 -203.4646 -91.09418 -203.4646 -203.46455z" fill-rule="evenodd"/><path fill="#000000" fill-opacity="0.0" d="m95.40751 8.810548l290.11023 0l0 288.18896l-290.11023 0z" fill-rule="evenodd"/><path fill="#ffffff" d="m308.04813 300.89618q-12.859375 15.421875 -36.375 23.921875q-23.5 8.484375 -52.09375 8.484375q-30.03125 0 -52.671875 -13.09375q-22.625 -13.109375 -34.9375 -38.046875q-12.312492 -24.9375 -12.624992 -58.625l0 -15.71875q0 -34.640625 11.671867 -59.96875q11.671875 -25.34375 33.671875 -38.765625q22.0 -13.421875 51.546875 -13.421875q41.140625 0 64.328125 19.625q23.203125 19.609375 27.484375 57.109375l-46.375 0q-3.171875 -19.859375 -14.0625 -29.0625q-10.875 -9.21875 -29.9375 -9.21875q-24.3125 0 -37.015625 18.265625q-12.703125 18.265625 -12.875 54.328125l0 14.765625q0 36.375 13.8125 54.96875q13.828125 18.578125 40.515625 18.578125q26.859375 0 38.296875 -11.4375l0 -39.875l-43.375 0l0 -35.09375l91.015625 0l0 92.28125z" fill-rule="nonzero"/><path fill="#000000" fill-opacity="0.0" d="m20.661194 84.271866l0 0c0 -36.022438 29.201962 -65.224396 65.2244 -65.224396l260.8898 0l0 0c17.298584 0 33.88864 6.8718376 46.120605 19.103786c12.231934 12.231945 19.10379 28.82203 19.10379 46.120613l0 260.88977c0 36.02243 -29.201965 65.224396 -65.224396 65.224396l-260.8898 0c-36.02244 0 -65.2244 -29.201965 -65.2244 -65.224396z" fill-rule="evenodd"/><path stroke="#ffffff" stroke-width="24.0" stroke-linejoin="round" stroke-linecap="butt" d="m20.661194 84.271866l0 0c0 -36.022438 29.201962 -65.224396 65.2244 -65.224396l260.8898 0l0 0c17.298584 0 33.88864 6.8718376 46.120605 19.103786c12.231934 12.231945 19.10379 28.82203 19.10379 46.120613l0 260.88977c0 36.02243 -29.201965 65.224396 -65.224396 65.224396l-260.8898 0c-36.02244 0 -65.2244 -29.201965 -65.2244 -65.224396z" fill-rule="evenodd"/></g></svg>
</a>
  <div class="navbar-nav-scroll">
    <ul class="navbar-nav bd-navbar-nav flex-row">
    
      <li class="nav-item">
        <a class="nav-link " href="/">Home</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-link " href="https://www.gen.dev/dev/">Documentation</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-link " href="/tutorials/">Tutorials</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-link " href="https://github.com/probcomp/Gen.jl">Source</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-link " href="/ecosystem/">Ecosystem</a>
      </li>
    
    </ul>
  </div>

</header>



<main role="main">
    <br/>
<div class="container">
<h1 id="tutorial-data-driven-proposals-in-gen-with-applications-to-inverse-planning">Tutorial: Data-Driven Proposals in Gen <em>(with applications to Inverse Planning)</em></h1>

<h3 id="what-is-this-tutorial-about">What is this tutorial about?</h3>

<p>In our 
<a href="Introduction%20to%20Modeling%20in%20Gen.jl">introduction to modeling tutorial</a>, we used <strong>Importance Sampling</strong> for inference: the inference engine <em>proposed</em> many possible explanations for a dataset, and then chose one. Importance sampling can be difficult to scale to more complex problems, because it is essentially “guessing and checking.” If we ran importance sampling with 1000 particles, for example, 
the method would fail unless those 1000 proposed solutions (blind guesses, essentially)
contained <em>something</em> close to the true answer. In complex problems, it is difficult
to “guess” (or “propose”) an entire solution all at once.</p>

<p>This tutorial addresses the scalability problem while staying inside
the importance sampling framework: the inference in this notebook is all importance
sampling, but with <strong>customized “data-driven” proposals</strong>. Such proposals 
can be used to accelerate Monte Carlo inference, making importance sampling
feasible for a broader class of models. Data-driven proposals work by incorporating 
information from the observed data set to make better proposals for the 
latent variables in a generative model. Data-driven proposals can be based on heuristics,
or general-purpose <em>discriminative</em> models, such as neural networks or random forests.
Many data-driven proposals have <strong>trainable parameters</strong>, which can be learned via gradient
descent using synthetic data simulated from the generative model itself. This training
process is sometimes called ‘amortized inference’ or ‘inference compilation’.</p>

<p>Although we focus on using data-driven proposals with importance sampling in this notebok,
data-driven proposals can also be used with Markov Chain Monte Carlo (MCMC) and
sequential Monte Carlo (SMC), covered in <a href="Iterative%20Inference%20in%20Gen.jl">other</a> <a href="Particle%20Filtering%20in%20Gen.jl">tutorials</a>.</p>

<h3 id="application-to-inverse-planning">Application to Inverse Planning</h3>
<p>This notebook begins by introducing a probabilistic model for the motion of 
an autonomous agent. The model itself demonstrates an important feature of
Gen: because it is embedded in Julia, we can use complex, black-box programs
as sub-routines in our models. The model we develop here uses an <em>RRT path planner</em>
to model the goal-directed motion of the agent.</p>

<p>After developing the model, we set out to improve the efficiency of inference. 
We show that we can improve the efficiency of inference in this model using
a custom proposal for the destination of the agent.</p>

<h2 id="outline">Outline</h2>

<p><strong>Section 1.</strong> <a href="#model">A generative model of an autonomous agent</a></p>

<p><strong>Section 2.</strong> <a href="#custom-proposal">Writing a data-driven proposal as a generative function</a></p>

<p><strong>Section 3.</strong> <a href="#using">Using a data-driven proposal within importance sampling</a></p>

<p><strong>Section 4.</strong> <a href="#training">Training the parameters of a data-driven proposal</a></p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># This cell will take a few seconds to run.</span>
<span class="n">using</span> <span class="n">Gen</span><span class="x">,</span> <span class="n">Distributions</span>
</code></pre></div></div>

<h2 id="1-a-generative-model-of-an-autonomous-agent---">1: A generative model of an autonomous agent   <a name="model"></a></h2>

<p>We begin by writing a generative probabilistic model of the motion of an
intelligent agent that is navigating a two-dimensional scene. The model will
be <em>algorithmic</em> — it will invoke a path planning algorithm implemented in
regular Julia code to generate the agent’s motion plan from its destination
and its map of the scene.</p>

<p>First, we load some basic geometric primitives for a two-dimensional scene. We
implemented these already in an auxiliary Julia file:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">include</span><span class="x">(</span><span class="s">"../inverse-planning/geometric_primitives.jl"</span><span class="x">);</span>
</code></pre></div></div>

<p>This file imports a two-dimensional <code class="highlighter-rouge">Point</code> data type with fields <code class="highlighter-rouge">x</code> and <code class="highlighter-rouge">y</code>:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">point</span> <span class="o">=</span> <span class="n">Point</span><span class="x">(</span><span class="mf">1.0</span><span class="x">,</span> <span class="mf">2.0</span><span class="x">)</span>
<span class="n">println</span><span class="x">(</span><span class="n">point</span><span class="o">.</span><span class="n">x</span><span class="x">)</span>
<span class="n">println</span><span class="x">(</span><span class="n">point</span><span class="o">.</span><span class="n">y</span><span class="x">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1.0
2.0
</code></pre></div></div>

<p>The file also defines an <code class="highlighter-rouge">Obstacle</code> data type, which represents a polygonal
obstacle in a two-dimensional scene, that is constructed from a list of
vertices. Here, we construct a square:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">obstacle</span> <span class="o">=</span> <span class="n">Obstacle</span><span class="x">([</span><span class="n">Point</span><span class="x">(</span><span class="mf">0.0</span><span class="x">,</span> <span class="mf">0.0</span><span class="x">),</span> <span class="n">Point</span><span class="x">(</span><span class="mf">1.0</span><span class="x">,</span> <span class="mf">0.0</span><span class="x">),</span> <span class="n">Point</span><span class="x">(</span><span class="mf">0.0</span><span class="x">,</span> <span class="mf">1.0</span><span class="x">),</span> <span class="n">Point</span><span class="x">(</span><span class="mf">1.0</span><span class="x">,</span> <span class="mf">1.0</span><span class="x">)]);</span>
</code></pre></div></div>

<p>Next, we load the definition of a <code class="highlighter-rouge">Scene</code> data type that represents a
two-dimensional scene.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">include</span><span class="x">(</span><span class="s">"../inverse-planning/scene.jl"</span><span class="x">);</span>
</code></pre></div></div>

<p>The scene spans a rectangle of on the two-dimensional x-y plane, and contains
a list of obstacles, which is initially empty:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scene</span> <span class="o">=</span> <span class="n">Scene</span><span class="x">(</span><span class="n">xmin</span><span class="o">=</span><span class="mi">0</span><span class="x">,</span> <span class="n">xmax</span><span class="o">=</span><span class="mi">1</span><span class="x">,</span> <span class="n">ymin</span><span class="o">=</span><span class="mi">0</span><span class="x">,</span> <span class="n">ymax</span><span class="o">=</span><span class="mi">1</span><span class="x">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Scene(0.0, 1.0, 0.0, 1.0, Obstacle[])
</code></pre></div></div>

<p>Obstacles are added to the scene with the <code class="highlighter-rouge">add_obstacle!</code> function:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">add_obstacle!</span><span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">obstacle</span><span class="x">);</span>
</code></pre></div></div>

<p>The file also defines functions that simplify the construction of obstacles:</p>

<p><code class="highlighter-rouge">make_square(center::Point, size::Float64)</code> constructs a square-shaped
obstacle centered at the given point with the given side length:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">obstacle</span> <span class="o">=</span> <span class="n">make_square</span><span class="x">(</span><span class="n">Point</span><span class="x">(</span><span class="mf">0.30</span><span class="x">,</span> <span class="mf">0.20</span><span class="x">),</span> <span class="mf">0.1</span><span class="x">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Obstacle(Point[Point(0.25, 0.15000000000000002), Point(0.35, 0.15000000000000002), Point(0.35, 0.25), Point(0.25, 0.25)])
</code></pre></div></div>

<p><code class="highlighter-rouge">make_line(vertical::Bool, start::Point, length::Float64,
thickness::Float64)</code> constructs an axis-aligned line (either vertical or
horizontal) with given thickness that extends from a given strating point for
a certain length:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">obstacle</span> <span class="o">=</span> <span class="n">make_line</span><span class="x">(</span><span class="n">false</span><span class="x">,</span> <span class="n">Point</span><span class="x">(</span><span class="mf">0.20</span><span class="x">,</span> <span class="mf">0.40</span><span class="x">),</span> <span class="mf">0.40</span><span class="x">,</span> <span class="mf">0.02</span><span class="x">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Obstacle(Point[Point(0.2, 0.4), Point(0.6000000000000001, 0.4), Point(0.6000000000000001, 0.42000000000000004), Point(0.2, 0.42000000000000004)])
</code></pre></div></div>

<p>We now construct a scene value that we will use in the rest of the notebook:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scene</span> <span class="o">=</span> <span class="n">Scene</span><span class="x">(</span><span class="n">xmin</span><span class="o">=</span><span class="mi">0</span><span class="x">,</span> <span class="n">xmax</span><span class="o">=</span><span class="mi">1</span><span class="x">,</span> <span class="n">ymin</span><span class="o">=</span><span class="mi">0</span><span class="x">,</span> <span class="n">ymax</span><span class="o">=</span><span class="mi">1</span><span class="x">)</span>
<span class="n">add_obstacle!</span><span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">make_square</span><span class="x">(</span><span class="n">Point</span><span class="x">(</span><span class="mf">0.30</span><span class="x">,</span> <span class="mf">0.20</span><span class="x">),</span> <span class="mf">0.1</span><span class="x">))</span>
<span class="n">add_obstacle!</span><span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">make_square</span><span class="x">(</span><span class="n">Point</span><span class="x">(</span><span class="mf">0.83</span><span class="x">,</span> <span class="mf">0.80</span><span class="x">),</span> <span class="mf">0.1</span><span class="x">))</span>
<span class="n">add_obstacle!</span><span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">make_square</span><span class="x">(</span><span class="n">Point</span><span class="x">(</span><span class="mf">0.80</span><span class="x">,</span> <span class="mf">0.40</span><span class="x">),</span> <span class="mf">0.1</span><span class="x">))</span>
<span class="n">horizontal</span> <span class="o">=</span> <span class="n">false</span>
<span class="n">vertical</span> <span class="o">=</span> <span class="n">true</span>
<span class="n">wall_thickness</span> <span class="o">=</span> <span class="mf">0.02</span>
<span class="n">add_obstacle!</span><span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">make_line</span><span class="x">(</span><span class="n">horizontal</span><span class="x">,</span> <span class="n">Point</span><span class="x">(</span><span class="mf">0.20</span><span class="x">,</span> <span class="mf">0.40</span><span class="x">),</span> <span class="mf">0.40</span><span class="x">,</span> <span class="n">wall_thickness</span><span class="x">))</span>
<span class="n">add_obstacle!</span><span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">make_line</span><span class="x">(</span><span class="n">vertical</span><span class="x">,</span> <span class="n">Point</span><span class="x">(</span><span class="mf">0.60</span><span class="x">,</span> <span class="mf">0.40</span><span class="x">),</span> <span class="mf">0.40</span><span class="x">,</span> <span class="n">wall_thickness</span><span class="x">))</span>
<span class="n">add_obstacle!</span><span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">make_line</span><span class="x">(</span><span class="n">horizontal</span><span class="x">,</span> <span class="n">Point</span><span class="x">(</span><span class="mf">0.60</span> <span class="o">-</span> <span class="mf">0.15</span><span class="x">,</span> <span class="mf">0.80</span><span class="x">),</span> <span class="mf">0.15</span> <span class="o">+</span> <span class="n">wall_thickness</span><span class="x">,</span> <span class="n">wall_thickness</span><span class="x">))</span>
<span class="n">add_obstacle!</span><span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">make_line</span><span class="x">(</span><span class="n">horizontal</span><span class="x">,</span> <span class="n">Point</span><span class="x">(</span><span class="mf">0.20</span><span class="x">,</span> <span class="mf">0.80</span><span class="x">),</span> <span class="mf">0.15</span><span class="x">,</span> <span class="n">wall_thickness</span><span class="x">))</span>
<span class="n">add_obstacle!</span><span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">make_line</span><span class="x">(</span><span class="n">vertical</span><span class="x">,</span> <span class="n">Point</span><span class="x">(</span><span class="mf">0.20</span><span class="x">,</span> <span class="mf">0.40</span><span class="x">),</span> <span class="mf">0.40</span><span class="x">,</span> <span class="n">wall_thickness</span><span class="x">));</span>
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># We visualize the scene below.</span>
<span class="n">include</span><span class="x">(</span><span class="s">"../inverse-planning/viz.jl"</span><span class="x">)</span>
<span class="n">visualize</span><span class="x">()</span> <span class="n">do</span> 
    <span class="n">draw_scene</span><span class="x">(</span><span class="n">scene</span><span class="x">)</span> 
<span class="k">end</span>
</code></pre></div></div>

<p><img src="output_31_0.png" alt="png" /></p>

<p>Next, we load a file that defines a <code class="highlighter-rouge">Path</code> data type (a sequence of
<code class="highlighter-rouge">Point</code>s), and a <code class="highlighter-rouge">plan_path</code> method, which  uses a path planning algorithm
based on rapidly exploring random tree (RRT, [1]) to find a sequence of
<code class="highlighter-rouge">Point</code>s beginning with <code class="highlighter-rouge">start</code> and ending in <code class="highlighter-rouge">dest</code> such that the line
segment between each consecutive pair of points does not intersect any
obstacles in the scene. The planning algorithm may fail to find a valid path,
in which case it will return a value of type <code class="highlighter-rouge">Nothing</code>.</p>

<p><code class="highlighter-rouge">path::Union{Path,Nothing} = plan_path(start::Point, dest::Point,
scene::Scene, planner_params::PlannerParams)</code></p>

<p>[1] <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.35.1853&amp;rep=rep1&amp;type=pdf"><em>Rapidly-exploring random trees: A new tool for path planning.</em></a>
S. M. LaValle. TR 98-11, Computer Science Dept., Iowa State University, October 1998.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">include</span><span class="x">(</span><span class="s">"../inverse-planning/planning.jl"</span><span class="x">);</span>
</code></pre></div></div>

<p>Let’s use <code class="highlighter-rouge">plan_path</code> to plan a path from the lower-left corner of the scene
into the interior of the box.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">start</span> <span class="o">=</span> <span class="n">Point</span><span class="x">(</span><span class="mf">0.1</span><span class="x">,</span> <span class="mf">0.1</span><span class="x">)</span>
<span class="n">dest</span> <span class="o">=</span> <span class="n">Point</span><span class="x">(</span><span class="mf">0.5</span><span class="x">,</span> <span class="mf">0.5</span><span class="x">)</span>
<span class="n">planner_params</span> <span class="o">=</span> <span class="n">PlannerParams</span><span class="x">(</span><span class="n">rrt_iters</span><span class="o">=</span><span class="mi">300</span><span class="x">,</span> <span class="n">rrt_dt</span><span class="o">=</span><span class="mf">3.0</span><span class="x">,</span>
                               <span class="n">refine_iters</span><span class="o">=</span><span class="mi">3500</span><span class="x">,</span> <span class="n">refine_std</span><span class="o">=</span><span class="mf">1.</span><span class="x">)</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">plan_path</span><span class="x">(</span><span class="n">start</span><span class="x">,</span> <span class="n">dest</span><span class="x">,</span> <span class="n">scene</span><span class="x">,</span> <span class="n">planner_params</span><span class="x">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Path(Point[Point(0.1, 0.1), Point(0.1253515594394693, 0.5164009936873899), Point(0.11095631971418911, 0.796900695279408), Point(0.30941512351219613, 0.8730219251057317), Point(0.3710285496975634, 0.8112721899208615), Point(0.5, 0.5)])
</code></pre></div></div>

<p>We visualize the path below. The start location is shown in blue, the
destination in red, and the path in orange. Run the cell above followed by
the cell below a few times to see the variability in the paths generated by
<code class="highlighter-rouge">plan_path</code> for these inputs.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">visualize</span><span class="x">()</span> <span class="n">do</span> 
    <span class="n">draw_trace</span><span class="x">(</span><span class="n">Dict</span><span class="x">(:</span><span class="n">start</span> <span class="o">=&gt;</span> <span class="n">start</span><span class="x">,</span> <span class="x">:</span><span class="n">dest</span> <span class="o">=&gt;</span> <span class="n">dest</span><span class="x">,</span> <span class="x">:</span><span class="n">scene</span> <span class="o">=&gt;</span> <span class="n">scene</span><span class="x">,</span> <span class="x">:</span><span class="n">path</span> <span class="o">=&gt;</span> <span class="n">path</span><span class="o">.</span><span class="n">points</span><span class="x">);</span> <span class="n">should_draw_measurements</span><span class="o">=</span><span class="n">false</span><span class="x">)</span>
<span class="k">end</span>
</code></pre></div></div>

<p><img src="output_37_0.png" alt="png" /></p>

<p>We also need a model for how the agent moves along its path.
We will assume that the agent moves along its path a constant speed. The file
loaded above also defines a method (<code class="highlighter-rouge">walk_path</code>) that computes the locations
of the agent at a set of timepoints (sampled at time intervals of <code class="highlighter-rouge">dt</code>
starting at time <code class="highlighter-rouge">0.</code>), given the path and the speed of the agent:</p>

<p><code class="highlighter-rouge">locations::Vector{Point} =  walk_path(path::Path, speed::Float64,
dt::Float64, num_ticks::Int)</code></p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">speed</span> <span class="o">=</span> <span class="mf">1.</span>
<span class="n">dt</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">num_ticks</span> <span class="o">=</span> <span class="mi">10</span><span class="x">;</span>
<span class="n">locations</span> <span class="o">=</span> <span class="n">walk_path</span><span class="x">(</span><span class="n">path</span><span class="x">,</span> <span class="n">speed</span><span class="x">,</span> <span class="n">dt</span><span class="x">,</span> <span class="n">num_ticks</span><span class="x">)</span>
<span class="n">println</span><span class="x">(</span><span class="n">locations</span><span class="x">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Point[Point(0.1, 0.1), Point(0.10607700387369604, 0.19981517932618803), Point(0.11215400774739206, 0.29963035865237614), Point(0.1182310116210881, 0.39944553797856425), Point(0.12430801549478411, 0.4992607173047523), Point(0.12110641528138277, 0.5991201211408362), Point(0.11598116190558816, 0.6989886936640975), Point(0.11278552471025023, 0.7976023085676063), Point(0.20615300301971937, 0.8334145131092261), Point(0.2995204813291885, 0.8692267176508457)]
</code></pre></div></div>

<p>Now, we are prepated to write our generative model for the motion of the agent.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@gen</span> <span class="k">function</span><span class="nf"> agent_model</span><span class="x">(</span>
        <span class="n">scene</span><span class="o">::</span><span class="n">Scene</span><span class="x">,</span> <span class="n">dt</span><span class="o">::</span><span class="kt">Float64</span><span class="x">,</span> <span class="n">num_ticks</span><span class="o">::</span><span class="kt">Int</span><span class="x">,</span> 
        <span class="n">planner_params</span><span class="o">::</span><span class="n">PlannerParams</span><span class="x">)</span>

    <span class="c"># sample the start point of the agent from the prior</span>
    <span class="n">start_x</span> <span class="o">~</span> <span class="n">uniform</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="mi">1</span><span class="x">)</span>
    <span class="n">start_y</span> <span class="o">~</span> <span class="n">uniform</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="mi">1</span><span class="x">)</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">Point</span><span class="x">(</span><span class="n">start_x</span><span class="x">,</span> <span class="n">start_y</span><span class="x">)</span>

    <span class="c"># sample the destination point of the agent from the prior</span>
    <span class="n">dest_x</span> <span class="o">~</span> <span class="n">uniform</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="mi">1</span><span class="x">)</span>
    <span class="n">dest_y</span> <span class="o">~</span> <span class="n">uniform</span><span class="x">(</span><span class="mi">0</span><span class="x">,</span> <span class="mi">1</span><span class="x">)</span>
    <span class="n">dest</span> <span class="o">=</span> <span class="n">Point</span><span class="x">(</span><span class="n">dest_x</span><span class="x">,</span> <span class="n">dest_y</span><span class="x">)</span>

    <span class="c"># plan a path that avoids obstacles in the scene</span>
    <span class="n">maybe_path</span> <span class="o">=</span> <span class="n">plan_path</span><span class="x">(</span><span class="n">start</span><span class="x">,</span> <span class="n">dest</span><span class="x">,</span> <span class="n">scene</span><span class="x">,</span> <span class="n">planner_params</span><span class="x">)</span>
    <span class="n">planning_failed</span> <span class="o">=</span> <span class="n">maybe_path</span> <span class="o">===</span> <span class="n">nothing</span>
    
    <span class="c"># sample the speed from the prior</span>
    <span class="n">speed</span> <span class="o">~</span> <span class="n">uniform</span><span class="x">(</span><span class="mf">0.3</span><span class="x">,</span> <span class="mi">1</span><span class="x">)</span>

    <span class="k">if</span> <span class="n">planning_failed</span>   
        <span class="c"># path planning failed; assume agent stays at start location indefinitely</span>
        <span class="n">locations</span> <span class="o">=</span> <span class="n">fill</span><span class="x">(</span><span class="n">start</span><span class="x">,</span> <span class="n">num_ticks</span><span class="x">)</span>
    <span class="k">else</span>   
        <span class="c"># path planning succeeded; move along the path at constant speed</span>
        <span class="n">locations</span> <span class="o">=</span> <span class="n">walk_path</span><span class="x">(</span><span class="n">maybe_path</span><span class="x">,</span> <span class="n">speed</span><span class="x">,</span> <span class="n">dt</span><span class="x">,</span> <span class="n">num_ticks</span><span class="x">)</span>
    <span class="k">end</span>

    <span class="c"># generate noisy measurements of the agent's location at each time point</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="mf">0.01</span>
    <span class="k">for</span> <span class="x">(</span><span class="n">i</span><span class="x">,</span> <span class="n">point</span><span class="x">)</span> <span class="k">in</span> <span class="n">enumerate</span><span class="x">(</span><span class="n">locations</span><span class="x">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="x">{:</span><span class="n">meas</span> <span class="o">=&gt;</span> <span class="x">(</span><span class="n">i</span><span class="x">,</span> <span class="x">:</span><span class="n">x</span><span class="x">)}</span> <span class="o">~</span> <span class="n">normal</span><span class="x">(</span><span class="n">point</span><span class="o">.</span><span class="n">x</span><span class="x">,</span> <span class="n">noise</span><span class="x">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="x">{:</span><span class="n">meas</span> <span class="o">=&gt;</span> <span class="x">(</span><span class="n">i</span><span class="x">,</span> <span class="x">:</span><span class="n">y</span><span class="x">)}</span> <span class="o">~</span> <span class="n">normal</span><span class="x">(</span><span class="n">point</span><span class="o">.</span><span class="n">y</span><span class="x">,</span> <span class="n">noise</span><span class="x">)</span>
    <span class="k">end</span>

    <span class="k">return</span> <span class="x">(</span><span class="n">planning_failed</span><span class="x">,</span> <span class="n">maybe_path</span><span class="x">)</span>
<span class="k">end</span><span class="x">;</span>
</code></pre></div></div>

<p>We can now perform a traced execution of <code class="highlighter-rouge">agent_model</code> and print out the
random choices it made:</p>

<h3 id="exercise">Exercise</h3>

<p>Using <code class="highlighter-rouge">simulate</code> (or <code class="highlighter-rouge">generate</code>, without any constraints) to sample a trace,
print the random choices made by this model. Parameterize the planner using
<code class="highlighter-rouge">PlannerParams</code> with the same parameters as above.</p>

<!-- # BEGIN ANSWER KEY 2A.1

planner_params = PlannerParams(rrt_iters=300, rrt_dt=3.0,
                               refine_iters=2000, refine_std=1.)
trace = Gen.simulate(agent_model, (scene, dt, num_ticks, planner_params));
choices = Gen.get_choices(trace)
display(choices)

# END ANSWER KEY -->
<hr />

<p>Next we explore the assumptions of the model by sampling many traces from the
generative function and visualizing them. We have created a specialized visualization
for traces of this generative function:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Let's visualize several traces of the function, with the start location fixed to</span>
<span class="c"># a point in the lower-left corner:</span>
<span class="n">constraints</span> <span class="o">=</span> <span class="n">Gen</span><span class="o">.</span><span class="n">choicemap</span><span class="x">()</span>
<span class="n">constraints</span><span class="x">[:</span><span class="n">start_x</span><span class="x">]</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">constraints</span><span class="x">[:</span><span class="n">start_y</span><span class="x">]</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="n">traces</span> <span class="o">=</span> <span class="x">[</span><span class="n">Gen</span><span class="o">.</span><span class="n">generate</span><span class="x">(</span><span class="n">agent_model</span><span class="x">,</span> <span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">dt</span><span class="x">,</span> <span class="n">num_ticks</span><span class="x">,</span> <span class="n">planner_params</span><span class="x">),</span> <span class="n">constraints</span><span class="x">)[</span><span class="mi">1</span><span class="x">]</span> <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="x">:</span><span class="mi">12</span><span class="x">];</span>
<span class="n">visualize_grid</span><span class="x">(</span><span class="n">traces</span><span class="x">,</span> <span class="mi">4</span><span class="x">,</span> <span class="mi">600</span><span class="x">;</span> <span class="n">separators</span><span class="o">=</span><span class="s">"gray"</span><span class="x">)</span> <span class="n">do</span> <span class="n">trace</span><span class="x">,</span> <span class="n">frame</span>
    <span class="n">draw_trace</span><span class="x">(</span><span class="n">trace</span><span class="x">,</span> <span class="n">frame</span><span class="x">;</span> <span class="n">draw_measurements</span><span class="o">=</span><span class="n">true</span><span class="x">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">6</span><span class="x">)</span>
<span class="k">end</span>
</code></pre></div></div>

<p><img src="output_46_0.png" alt="png" /></p>

<p>In this visualization, the start location is represented by a blue dot, and
the destination is represented by a red dot. The measured coordinates at each
time point are represented by black dots. The path, if path planning was
succesful, is shown as a gray line from the start point to the destination
point. Notice that the speed of the agent is different in each case. Also note that
the we observe the agent for a fixed amount of time, in which they may or may not
finish walking their planned path.</p>

<hr />

<h3 id="exercise-1">Exercise</h3>

<p>Edit the constraints passed to the inference algorithm:</p>

<ol>
  <li>Constrain the start of the agent to be at $x = 0.9$, $y = 0.1$.</li>
  <li>Constrain the destination of the agent to be at $x = 0.9$, $y = 0.8$.</li>
</ol>

<p>Visualize the resulting prior. We have provided some starter code.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># &lt; put your code here&gt;</span>
<span class="n">traces_constrained</span> <span class="o">=</span> <span class="x">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="x">:</span><span class="mi">12</span>
    <span class="c"># Modify the following line:</span>
    <span class="x">(</span><span class="n">trace_constrained</span><span class="x">,</span> <span class="n">_</span><span class="x">)</span> <span class="o">=</span> <span class="n">Gen</span><span class="o">.</span><span class="n">generate</span><span class="x">(</span><span class="n">agent_model</span><span class="x">,</span> <span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">dt</span><span class="x">,</span> <span class="n">num_ticks</span><span class="x">,</span> <span class="n">planner_params</span><span class="x">))</span>
    <span class="n">push!</span><span class="x">(</span><span class="n">traces_constrained</span><span class="x">,</span> <span class="n">trace_constrained</span><span class="x">)</span>
<span class="k">end</span>

<span class="c"># Visualize:</span>
<span class="n">visualize_grid</span><span class="x">(</span><span class="n">traces_constrained</span><span class="x">,</span> <span class="mi">4</span><span class="x">,</span> <span class="mi">600</span><span class="x">;</span> <span class="n">separators</span><span class="o">=</span><span class="s">"gray"</span><span class="x">)</span> <span class="n">do</span> <span class="n">trace</span><span class="x">,</span> <span class="n">frame</span>
    <span class="n">draw_trace</span><span class="x">(</span><span class="n">trace</span><span class="x">,</span> <span class="n">frame</span><span class="x">;</span> <span class="n">draw_measurements</span><span class="o">=</span><span class="n">true</span><span class="x">)</span>
<span class="k">end</span>
</code></pre></div></div>

<p><img src="output_49_0.png" alt="png" /></p>

<!-- # BEGIN ANSWER KEY 2A.2

constraints = Gen.choicemap()
constraints[:start_x] = 0.9
constraints[:start_y] = 0.1

constraints[:dest_x] = 0.9
constraints[:dest_y] = 0.8

traces_constrained = []
for i in 1:12
    # Modify the following line:
    (trace_constrained, _) = Gen.generate(agent_model, (scene, dt, num_ticks, planner_params), constraints)
    push!(traces_constrained, trace_constrained)
end

# Visualize:
visualize_grid(traces_constrained, 4, 600; separators="gray") do trace, frame
    draw_trace(trace, frame; draw_measurements=true)
end

# END ANSWER KEY -->
<hr />

<h3 id="exercise-2">Exercise</h3>
<p>The <code class="highlighter-rouge">rrt_iters</code> field of <code class="highlighter-rouge">PlannerParams</code> is the number of iterations of the RRT
algorithm to use. The <code class="highlighter-rouge">refine_iters</code> field of <code class="highlighter-rouge">PlannerParams</code> is the number of
iterations of path refinement. These parameters affect the distribution on
paths of the agent. Visualize traces of the <code class="highlighter-rouge">agent_model</code> with a couple of
different settings of these two parameters to the path planning algorithm for
fixed starting point and destination point. Try setting them to smaller
values. Discuss.</p>

<p>We have provided starter code.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">constraints</span> <span class="o">=</span> <span class="n">Gen</span><span class="o">.</span><span class="n">choicemap</span><span class="x">()</span>
<span class="n">constraints</span><span class="x">[:</span><span class="n">start_x</span><span class="x">]</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">constraints</span><span class="x">[:</span><span class="n">start_y</span><span class="x">]</span> <span class="o">=</span> <span class="mf">0.1</span><span class="x">;</span>
</code></pre></div></div>

<p>Modify the <code class="highlighter-rouge">PlannerParams</code> in the cell below.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">planner_params</span> <span class="o">=</span> <span class="n">PlannerParams</span><span class="x">(</span><span class="n">rrt_iters</span><span class="o">=</span><span class="mi">300</span><span class="x">,</span> <span class="n">rrt_dt</span><span class="o">=</span><span class="mf">3.0</span><span class="x">,</span> <span class="n">refine_iters</span><span class="o">=</span><span class="mi">2000</span><span class="x">,</span> <span class="n">refine_std</span><span class="o">=</span><span class="mf">1.</span><span class="x">)</span> <span class="c"># &lt; change this line&gt;</span>

<span class="n">traces</span> <span class="o">=</span> <span class="x">[</span><span class="n">Gen</span><span class="o">.</span><span class="n">generate</span><span class="x">(</span><span class="n">agent_model</span><span class="x">,</span> <span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">dt</span><span class="x">,</span> <span class="n">num_ticks</span><span class="x">,</span> <span class="n">planner_params</span><span class="x">),</span> <span class="n">constraints</span><span class="x">)[</span><span class="mi">1</span><span class="x">]</span> <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="x">:</span><span class="mi">12</span><span class="x">];</span>
<span class="n">visualize_grid</span><span class="x">(</span><span class="n">traces</span><span class="x">,</span> <span class="mi">4</span><span class="x">,</span> <span class="mi">600</span><span class="x">;</span> <span class="n">separators</span><span class="o">=</span><span class="s">"gray"</span><span class="x">)</span> <span class="n">do</span> <span class="n">trace</span><span class="x">,</span> <span class="n">frame</span> 
    <span class="n">draw_trace</span><span class="x">(</span><span class="n">trace</span><span class="x">,</span> <span class="n">frame</span><span class="x">;</span> <span class="n">draw_measurements</span><span class="o">=</span><span class="n">true</span><span class="x">)</span>
<span class="k">end</span>
</code></pre></div></div>

<p><img src="output_55_0.png" alt="png" /></p>

<hr />

<p>For the next few sections of the notebook, let’s reset any variables that may have changed during your exploration with the model.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">start</span> <span class="o">=</span> <span class="n">Point</span><span class="x">(</span><span class="mf">0.1</span><span class="x">,</span> <span class="mf">0.1</span><span class="x">)</span>
<span class="n">dt</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">num_ticks</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">planner_params</span> <span class="o">=</span> <span class="n">PlannerParams</span><span class="x">(</span><span class="n">rrt_iters</span><span class="o">=</span><span class="mi">600</span><span class="x">,</span> <span class="n">rrt_dt</span><span class="o">=</span><span class="mf">0.05</span><span class="x">,</span>
                               <span class="n">refine_iters</span><span class="o">=</span><span class="mi">3500</span><span class="x">,</span> <span class="n">refine_std</span><span class="o">=</span><span class="mf">1.</span><span class="x">);</span>
</code></pre></div></div>

<p>We will infer the destination of the agent for the given sequence of observed locations:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">measurements</span> <span class="o">=</span> <span class="x">[</span>
    <span class="n">Point</span><span class="x">(</span><span class="mf">0.0980245</span><span class="x">,</span> <span class="mf">0.104775</span><span class="x">),</span>
    <span class="n">Point</span><span class="x">(</span><span class="mf">0.113734</span><span class="x">,</span> <span class="mf">0.150773</span><span class="x">),</span>
    <span class="n">Point</span><span class="x">(</span><span class="mf">0.100412</span><span class="x">,</span> <span class="mf">0.195499</span><span class="x">),</span>
    <span class="n">Point</span><span class="x">(</span><span class="mf">0.114794</span><span class="x">,</span> <span class="mf">0.237386</span><span class="x">),</span>
    <span class="n">Point</span><span class="x">(</span><span class="mf">0.0957668</span><span class="x">,</span> <span class="mf">0.277711</span><span class="x">),</span>
    <span class="n">Point</span><span class="x">(</span><span class="mf">0.140181</span><span class="x">,</span> <span class="mf">0.31304</span><span class="x">),</span>
    <span class="n">Point</span><span class="x">(</span><span class="mf">0.124384</span><span class="x">,</span> <span class="mf">0.356242</span><span class="x">),</span>
    <span class="n">Point</span><span class="x">(</span><span class="mf">0.122272</span><span class="x">,</span> <span class="mf">0.414463</span><span class="x">),</span>
    <span class="n">Point</span><span class="x">(</span><span class="mf">0.124597</span><span class="x">,</span> <span class="mf">0.462056</span><span class="x">),</span>
    <span class="n">Point</span><span class="x">(</span><span class="mf">0.126227</span><span class="x">,</span> <span class="mf">0.498338</span><span class="x">)];</span>
</code></pre></div></div>

<hr />

<h3 id="exercise-3">Exercise</h3>

<p>Run inference using Gen’s built-in importance resampling implementation. Use
50 importance samples (<code class="highlighter-rouge">amt_computation</code>).</p>

<p>To see how to use the built-in importance resampling function, run
<code class="highlighter-rouge">?Gen.importance_resampling</code> or check out the
<a href="https://www.gen.dev/dev/ref/importance/#Gen.importance_resampling">documentation</a>.</p>

<p>We have provided some starter code.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span><span class="nf"> do_inference</span><span class="x">(</span>
        <span class="n">scene</span><span class="o">::</span><span class="n">Scene</span><span class="x">,</span> <span class="n">dt</span><span class="o">::</span><span class="kt">Float64</span><span class="x">,</span> <span class="n">num_ticks</span><span class="o">::</span><span class="kt">Int</span><span class="x">,</span> 
        <span class="n">planner_params</span><span class="o">::</span><span class="n">PlannerParams</span><span class="x">,</span> 
        <span class="n">start</span><span class="o">::</span><span class="n">Point</span><span class="x">,</span> <span class="n">measurements</span><span class="o">::</span><span class="n">Vector</span><span class="x">{</span><span class="n">Point</span><span class="x">},</span> <span class="n">amount_of_computation</span><span class="o">::</span><span class="kt">Int</span><span class="x">)</span>
    
    <span class="c"># Constrain the observed measurements.</span>
    <span class="n">observations</span> <span class="o">=</span> <span class="n">Gen</span><span class="o">.</span><span class="n">choicemap</span><span class="x">()</span>
    <span class="n">observations</span><span class="x">[:</span><span class="n">start_x</span><span class="x">]</span> <span class="o">=</span> <span class="n">start</span><span class="o">.</span><span class="n">x</span>
    <span class="n">observations</span><span class="x">[:</span><span class="n">start_y</span><span class="x">]</span> <span class="o">=</span> <span class="n">start</span><span class="o">.</span><span class="n">y</span>
    <span class="k">for</span> <span class="x">(</span><span class="n">i</span><span class="x">,</span> <span class="n">m</span><span class="x">)</span> <span class="k">in</span> <span class="n">enumerate</span><span class="x">(</span><span class="n">measurements</span><span class="x">)</span>
        <span class="n">observations</span><span class="x">[:</span><span class="n">meas</span> <span class="o">=&gt;</span> <span class="x">(</span><span class="n">i</span><span class="x">,</span> <span class="x">:</span><span class="n">x</span><span class="x">)]</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">x</span>
        <span class="n">observations</span><span class="x">[:</span><span class="n">meas</span> <span class="o">=&gt;</span> <span class="x">(</span><span class="n">i</span><span class="x">,</span> <span class="x">:</span><span class="n">y</span><span class="x">)]</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">y</span>
    <span class="k">end</span>
    
    <span class="c"># &lt; put your code here&gt;</span>
    
    <span class="k">return</span> <span class="n">trace</span>
<span class="k">end</span><span class="x">;</span>
</code></pre></div></div>

<!-- # BEGIN ANSWER KEY 2A.3

function do_inference(
        scene::Scene, dt::Float64, num_ticks::Int, 
        planner_params::PlannerParams, 
        start::Point, measurements::Vector{Point}, amount_of_computation::Int)
    
    # Constrain the observed measurements.
    observations = Gen.choicemap()
    observations[:start_x] = start.x
    observations[:start_y] = start.y
    for (i, m) in enumerate(measurements)
        observations[:meas => (i, :x)] = m.x
        observations[:meas => (i, :y)] = m.y
    end
    
    # Call importance_resampling to obtain a likely trace consistent
    # with our observations.
    (trace, _) = Gen.importance_resampling(
        agent_model, (scene, dt, num_ticks, planner_params),
        observations, amount_of_computation)
    
    return trace
end;

# END ANSWER KEY -->
<h4 id="visualize-your-answer">Visualize your answer</h4>
<p>Below, we run this algorithm 1000 times, to generate 1000 approximate samples
from the posterior distribution on the destination. The inferred destinations
should appear as red dots on the map. First, we abstract this into a
function.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span><span class="nf"> visualize_inference</span><span class="x">(</span><span class="n">measurements</span><span class="x">,</span> <span class="n">scene</span><span class="x">,</span> <span class="n">start</span><span class="x">;</span> <span class="n">computation_amt</span><span class="o">=</span><span class="mi">50</span><span class="x">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">1000</span><span class="x">)</span>
    <span class="n">visualize</span><span class="x">()</span> <span class="n">do</span>
        <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="x">:</span><span class="n">samples</span>
            <span class="n">trace</span> <span class="o">=</span> <span class="n">do_inference</span><span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">dt</span><span class="x">,</span> <span class="n">num_ticks</span><span class="x">,</span> <span class="n">planner_params</span><span class="x">,</span> <span class="n">start</span><span class="x">,</span> <span class="n">measurements</span><span class="x">,</span> <span class="n">computation_amt</span><span class="x">)</span>
            <span class="n">draw_trace</span><span class="x">(</span><span class="n">trace</span><span class="x">;</span> <span class="n">draw_measurements</span><span class="o">=</span><span class="n">true</span><span class="x">,</span> <span class="n">draw_path</span><span class="o">=</span><span class="n">false</span><span class="x">)</span>
        <span class="k">end</span>
    <span class="k">end</span>
<span class="k">end</span><span class="x">;</span>
</code></pre></div></div>

<p>And now we run it! Note that this might take a while.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">visualize_inference</span><span class="x">(</span><span class="n">measurements</span><span class="x">,</span> <span class="n">scene</span><span class="x">,</span> <span class="n">start</span><span class="x">,</span> <span class="n">computation_amt</span><span class="o">=</span><span class="mi">50</span><span class="x">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">500</span><span class="x">)</span>
</code></pre></div></div>

<p><img src="output_67_0.png" alt="png" /></p>

<p>The algorithm has made reasonable inferences about where the agent was likely
trying to go.</p>

<p>Note that the above illustration takes a while to produce. This is
because each dot requires sampling 50 times from the default proposal (which
runs the RRT planner). When our models contain more expensive components, like
the path-planner, the computational demands of inference increase accordingly.
This motivates us to find more efficient inference algorithms, that will
require fewer model evaluations to produce good results.</p>

<hr />

<h3 id="exercise-4">Exercise</h3>

<p>In this problem, you’ll explore the effect of changing the <em>scene</em> on the
inferences we make about the agent. Below, we’ve reproduced the code for
constructing the scene in which we performed inference above. Modify the scene
so that there is an opening into the “room” along the <em>bottom</em> wall, in
addition to the already-existing door along top wall. Otherwise, the scene
should be identical to the one above.</p>

<p>Rerun inference. The results should be qualitatively different from the
results generated above, even though the observed movements of the agent are
identical. <strong>Write a one- or two-sentence description of how the results are
different, and why.</strong> Please address:</p>

<ol>
  <li>Why would a <em>human</em> make different inferences about the agent’s likely
destination in the two different scenes?</li>
  <li>To what extent does the <em>model</em> succeed in producing qualitiatively
different results in the two scenes? Why? (Concretely, why are certain
proposals more often rejected by importance sampling in the two-door scene
than in the one-door scene?)</li>
</ol>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scene_2doors</span> <span class="o">=</span> <span class="n">Scene</span><span class="x">(</span><span class="n">xmin</span><span class="o">=</span><span class="mi">0</span><span class="x">,</span> <span class="n">xmax</span><span class="o">=</span><span class="mi">1</span><span class="x">,</span> <span class="n">ymin</span><span class="o">=</span><span class="mi">0</span><span class="x">,</span> <span class="n">ymax</span><span class="o">=</span><span class="mi">1</span><span class="x">)</span>

<span class="c"># Add the three blocks.</span>
<span class="n">add_obstacle!</span><span class="x">(</span><span class="n">scene_2doors</span><span class="x">,</span> <span class="n">make_square</span><span class="x">(</span><span class="n">Point</span><span class="x">(</span><span class="mf">0.30</span><span class="x">,</span> <span class="mf">0.20</span><span class="x">),</span> <span class="mf">0.1</span><span class="x">))</span>
<span class="n">add_obstacle!</span><span class="x">(</span><span class="n">scene_2doors</span><span class="x">,</span> <span class="n">make_square</span><span class="x">(</span><span class="n">Point</span><span class="x">(</span><span class="mf">0.83</span><span class="x">,</span> <span class="mf">0.80</span><span class="x">),</span> <span class="mf">0.1</span><span class="x">))</span>
<span class="n">add_obstacle!</span><span class="x">(</span><span class="n">scene_2doors</span><span class="x">,</span> <span class="n">make_square</span><span class="x">(</span><span class="n">Point</span><span class="x">(</span><span class="mf">0.80</span><span class="x">,</span> <span class="mf">0.40</span><span class="x">),</span> <span class="mf">0.1</span><span class="x">))</span>

<span class="c"># Add the walls. You will need to change this code. In particular, you will need to edit </span>
<span class="c"># one of these lines (the one that constructs the bottom wall of the room) and add one new line</span>
<span class="c"># (because in order to create the "door", you will actually need to represent the bottom wall</span>
<span class="c"># as two separate rectangular obstacles -- as the sample code already does for the top wall).</span>
<span class="n">horizontal</span> <span class="o">=</span> <span class="n">false</span>
<span class="n">vertical</span> <span class="o">=</span> <span class="n">true</span>
<span class="n">wall_thickness</span> <span class="o">=</span> <span class="mf">0.02</span>
<span class="n">add_obstacle!</span><span class="x">(</span><span class="n">scene_2doors</span><span class="x">,</span> <span class="n">make_line</span><span class="x">(</span><span class="n">horizontal</span><span class="x">,</span> <span class="n">Point</span><span class="x">(</span><span class="mf">0.20</span><span class="x">,</span> <span class="mf">0.40</span><span class="x">),</span> <span class="mf">0.40</span><span class="x">,</span> <span class="n">wall_thickness</span><span class="x">))</span>
<span class="n">add_obstacle!</span><span class="x">(</span><span class="n">scene_2doors</span><span class="x">,</span> <span class="n">make_line</span><span class="x">(</span><span class="n">vertical</span><span class="x">,</span> <span class="n">Point</span><span class="x">(</span><span class="mf">0.60</span><span class="x">,</span> <span class="mf">0.40</span><span class="x">),</span> <span class="mf">0.40</span><span class="x">,</span> <span class="n">wall_thickness</span><span class="x">))</span>
<span class="n">add_obstacle!</span><span class="x">(</span><span class="n">scene_2doors</span><span class="x">,</span> <span class="n">make_line</span><span class="x">(</span><span class="n">horizontal</span><span class="x">,</span> <span class="n">Point</span><span class="x">(</span><span class="mf">0.60</span> <span class="o">-</span> <span class="mf">0.15</span><span class="x">,</span> <span class="mf">0.80</span><span class="x">),</span> <span class="mf">0.15</span> <span class="o">+</span> <span class="n">wall_thickness</span><span class="x">,</span> <span class="n">wall_thickness</span><span class="x">))</span>
<span class="n">add_obstacle!</span><span class="x">(</span><span class="n">scene_2doors</span><span class="x">,</span> <span class="n">make_line</span><span class="x">(</span><span class="n">horizontal</span><span class="x">,</span> <span class="n">Point</span><span class="x">(</span><span class="mf">0.20</span><span class="x">,</span> <span class="mf">0.80</span><span class="x">),</span> <span class="mf">0.15</span><span class="x">,</span> <span class="n">wall_thickness</span><span class="x">))</span>
<span class="n">add_obstacle!</span><span class="x">(</span><span class="n">scene_2doors</span><span class="x">,</span> <span class="n">make_line</span><span class="x">(</span><span class="n">vertical</span><span class="x">,</span> <span class="n">Point</span><span class="x">(</span><span class="mf">0.20</span><span class="x">,</span> <span class="mf">0.40</span><span class="x">),</span> <span class="mf">0.40</span><span class="x">,</span> <span class="n">wall_thickness</span><span class="x">));</span>
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Perform and visualize inference:</span>
<span class="n">visualize_inference</span><span class="x">(</span><span class="n">measurements</span><span class="x">,</span> <span class="n">scene_2doors</span><span class="x">,</span> <span class="n">start</span><span class="x">,</span> <span class="n">computation_amt</span><span class="o">=</span><span class="mi">100</span><span class="x">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">500</span><span class="x">)</span>
</code></pre></div></div>

<p><img src="output_75_0.png" alt="png" /></p>

<p><strong>Free response:</strong> What changed about the inferences when you changed the scene,
and why? You might address:</p>

<ol>
  <li>Why would a <em>human</em> make different inferences about the agent’s likely
destination in the two different scenes?</li>
  <li>To what extent does the <em>model</em> succeed in producing qualitiatively
different results in the two scenes? (Concretely, why are certain proposals
more often rejected by importance sampling in the two-door scene than in
the one-door scene?)</li>
</ol>

<hr />

<!-- # BEGIN ANSWER KEY 2.4

scene_2doors = Scene(xmin=0, xmax=1, ymin=0, ymax=1)

# Add the three blocks.
add_obstacle!(scene_2doors, make_square(Point(0.30, 0.20), 0.1))
add_obstacle!(scene_2doors, make_square(Point(0.83, 0.80), 0.1))
add_obstacle!(scene_2doors, make_square(Point(0.80, 0.40), 0.1))

horizontal = false
vertical = true
wall_thickness = 0.02
add_obstacle!(scene_2doors, make_line(horizontal, Point(0.60 - 0.15, 0.40), 0.15 + wall_thickness, wall_thickness))
add_obstacle!(scene_2doors, make_line(horizontal, Point(0.20, 0.40), 0.15, wall_thickness))
add_obstacle!(scene_2doors, make_line(vertical, Point(0.60, 0.40), 0.40, wall_thickness))
add_obstacle!(scene_2doors, make_line(horizontal, Point(0.60 - 0.15, 0.80), 0.15 + wall_thickness, wall_thickness))
add_obstacle!(scene_2doors, make_line(horizontal, Point(0.20, 0.80), 0.15, wall_thickness))
add_obstacle!(scene_2doors, make_line(vertical, Point(0.20, 0.40), 0.40, wall_thickness))

# Perform and visualize inference:
visualize_inference(measurements, scene_2doors, start, computation_amt=50, samples=100)

# END ANSWER KEY -->

<h2 id="2-writing-a-data-driven-proposal-as-a-generative-function-">2. Writing a data-driven proposal as a generative function <a name="custom-proposal"></a></h2>

<p>The inference algorithm above used a variant of
<a href="https://probcomp.github.io/Gen/dev/ref/importance/#Gen.importance_resampling"><code class="highlighter-rouge">Gen.importance_resampling</code></a>
that does not take a custom proposal distribution. It uses the default
proposal distribution associated with the generative model. For generative
functions defined using the built-in modeling DSL, the default proposal
distribution is based on <em>ancestral sampling</em>, which involves sampling
unconstrained random choices from the distributions specified in the
generative model. Put more simply, each “guess” the inference algorithm
makes about the possible destination of the agent is totally uninformed
by the observed measurements; it is sampled using the prior generative
model’s <code class="highlighter-rouge">dest_x</code> and <code class="highlighter-rouge">dest_y</code> sampling statements.</p>

<p>We can visualize this default proposal distribution by sampling from it, 
using <code class="highlighter-rouge">Gen.generate</code> (note, we also could use <code class="highlighter-rouge">Gen.simulate</code> for the same purpose, since we are not passing any constraints). The cell below shows samples of the agent’s destination 
drawn from this distribution.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">include</span><span class="x">(</span><span class="s">"../inverse-planning/viz.jl"</span><span class="x">);</span>

<span class="n">traces</span> <span class="o">=</span> <span class="x">[</span><span class="n">Gen</span><span class="o">.</span><span class="n">generate</span><span class="x">(</span><span class="n">agent_model</span><span class="x">,</span> <span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">dt</span><span class="x">,</span> <span class="n">num_ticks</span><span class="x">,</span> <span class="n">planner_params</span><span class="x">))[</span><span class="mi">1</span><span class="x">]</span> <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="x">:</span><span class="mi">1000</span><span class="x">]</span>
<span class="n">visualize</span><span class="x">()</span> <span class="n">do</span>

    <span class="k">for</span> <span class="n">i</span> <span class="k">in</span> <span class="mi">1</span><span class="x">:</span><span class="mi">1000</span>
        <span class="n">trace</span><span class="x">,</span> <span class="o">=</span> <span class="n">Gen</span><span class="o">.</span><span class="n">generate</span><span class="x">(</span><span class="n">agent_model</span><span class="x">,</span> <span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">dt</span><span class="x">,</span> <span class="n">num_ticks</span><span class="x">,</span> <span class="n">planner_params</span><span class="x">))</span>
        <span class="n">draw_dest</span><span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">Point</span><span class="x">(</span><span class="n">trace</span><span class="x">[:</span><span class="n">dest_x</span><span class="x">],</span> <span class="n">trace</span><span class="x">[:</span><span class="n">dest_y</span><span class="x">]))</span>
    <span class="k">end</span>

    <span class="n">draw_scene</span><span class="x">(</span><span class="n">scene</span><span class="x">)</span>
    <span class="n">draw_start</span><span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">start</span><span class="x">)</span>
    <span class="n">draw_measurements</span><span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">measurements</span><span class="x">)</span>
<span class="k">end</span>
</code></pre></div></div>

<p><img src="output_81_0.png" alt="png" /></p>

<p>Intuitively, if we see the data set above (where blue is the starting
location, and the measurements are black crosses), we might guess that the 
agent is more likely to be heading into the upper part of the scene. This 
is because we don’t expect the agent to unecessarily backtrack on its route
to its destnation. A simple heuristic for biasing the proposal distribution 
of the destination using just the first measurement and the last measurement might be:</p>

<ul>
  <li>
    <p>If the x-coordinate of the last measurement is greater than the
x-coordinate of the first measurement, we think the agent is probably
headed generally to the right. Make values <code class="highlighter-rouge">:dest_x</code> that are greater than
the x-coordinate of the last measurement more probable.</p>
  </li>
  <li>
    <p>If the x-coordinate of the last measurment is less than the x-coordinate of
the first measurement, we think the agent is probably headed generally to
the left. Make values  <code class="highlighter-rouge">:dest_x</code> that are smaller than the x-coordinate of
the last measurement more probable.</p>
  </li>
</ul>

<p>We can apply the same heuristic separately for the y-coordinate.</p>

<p>To implement this idea, we discretize the x-axis and y-axis of the scene into
bins:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_x_bins</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">num_y_bins</span> <span class="o">=</span> <span class="mi">5</span><span class="x">;</span>
</code></pre></div></div>

<p>We will propose the x-coordinate of the destination from a
<a href="https://www.gen.dev/dev/ref/distributions/#Gen.piecewise_uniform">piecewise_uniform</a>
distribution, where we set higher probability for certain bins based on the
heuristic described above and use a uniform continuous distribution for the
coordinate within a bin. The <code class="highlighter-rouge">compute_bin_probs</code> function below computes the
probability for each bin. The bounds of the scene are given by <code class="highlighter-rouge">min</code> and
<code class="highlighter-rouge">max</code>. The coordinates of the first and last measured points respectively are
given by <code class="highlighter-rouge">first</code> and <code class="highlighter-rouge">last</code>. We compute the probability by assigning a
“score” to each bin based on the heuristic above — if the bin should
receive lower probability, it gets a score of 1., and if it should receive
higher probability, it gets a bin of <code class="highlighter-rouge">score_high</code>, where <code class="highlighter-rouge">score_high</code> is some
value greater than 1.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span><span class="nf"> compute_bin_prob</span><span class="x">(</span><span class="n">first</span><span class="o">::</span><span class="kt">Float64</span><span class="x">,</span> <span class="n">last</span><span class="o">::</span><span class="kt">Float64</span><span class="x">,</span> <span class="n">bin</span><span class="o">::</span><span class="kt">Int</span><span class="x">,</span> <span class="n">last_bin</span><span class="o">::</span><span class="kt">Int</span><span class="x">,</span> <span class="n">score_high</span><span class="x">)</span>
    <span class="n">last</span> <span class="o">&gt;=</span> <span class="n">first</span> <span class="o">&amp;&amp;</span> <span class="n">bin</span> <span class="o">&gt;=</span> <span class="n">last_bin</span> <span class="o">&amp;&amp;</span> <span class="k">return</span> <span class="n">score_high</span>
    <span class="n">last</span> <span class="o">&lt;</span> <span class="n">first</span> <span class="o">&amp;&amp;</span> <span class="n">bin</span> <span class="o">&lt;=</span> <span class="n">last_bin</span> <span class="o">&amp;&amp;</span> <span class="k">return</span> <span class="n">score_high</span>
    <span class="k">return</span> <span class="mf">1.</span>
<span class="k">end</span>

<span class="k">function</span><span class="nf"> compute_bin_probs</span><span class="x">(</span><span class="n">num_bins</span><span class="o">::</span><span class="kt">Int</span><span class="x">,</span> <span class="n">min</span><span class="o">::</span><span class="kt">Float64</span><span class="x">,</span> <span class="n">max</span><span class="o">::</span><span class="kt">Float64</span><span class="x">,</span> <span class="n">first</span><span class="o">::</span><span class="kt">Float64</span><span class="x">,</span> <span class="n">last</span><span class="o">::</span><span class="kt">Float64</span><span class="x">,</span> <span class="n">score_high</span><span class="x">)</span>
    <span class="n">bin_len</span> <span class="o">=</span> <span class="x">(</span><span class="n">max</span> <span class="o">-</span> <span class="n">min</span><span class="x">)</span> <span class="o">/</span> <span class="n">num_bins</span>
    <span class="n">last_bin</span> <span class="o">=</span> <span class="kt">Int</span><span class="x">(</span><span class="n">floor</span><span class="x">(</span><span class="n">last</span> <span class="o">/</span> <span class="n">bin_len</span><span class="x">))</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="x">[</span><span class="n">compute_bin_prob</span><span class="x">(</span><span class="n">first</span><span class="x">,</span> <span class="n">last</span><span class="x">,</span> <span class="n">bin</span><span class="x">,</span> <span class="n">last_bin</span><span class="x">,</span> <span class="n">score_high</span><span class="x">)</span> <span class="k">for</span> <span class="n">bin</span><span class="o">=</span><span class="mi">1</span><span class="x">:</span><span class="n">num_bins</span><span class="x">]</span>
    <span class="n">total</span> <span class="o">=</span> <span class="n">sum</span><span class="x">(</span><span class="n">probs</span><span class="x">)</span>
    <span class="k">return</span> <span class="x">[</span><span class="n">p</span> <span class="o">/</span> <span class="n">total</span> <span class="k">for</span> <span class="n">p</span> <span class="k">in</span> <span class="n">probs</span><span class="x">]</span>
<span class="k">end</span><span class="x">;</span>
</code></pre></div></div>

<p>We will see how to automatically tune the value of <code class="highlighter-rouge">score_high</code> shortly. For
now, we will use a value of 5. Below, we see that for the data set of
measurements, shown above the probabilities of higher bins are indeed 5x
larger than those of lower bins, becuase the agent seems to be headed up.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">compute_bin_probs</span><span class="x">(</span><span class="n">num_y_bins</span><span class="x">,</span> <span class="n">scene</span><span class="o">.</span><span class="n">ymin</span><span class="x">,</span> <span class="n">scene</span><span class="o">.</span><span class="n">ymax</span><span class="x">,</span> <span class="n">measurements</span><span class="x">[</span><span class="mi">1</span><span class="x">]</span><span class="o">.</span><span class="n">y</span><span class="x">,</span> <span class="n">measurements</span><span class="x">[</span><span class="k">end</span><span class="x">]</span><span class="o">.</span><span class="n">y</span><span class="x">,</span> <span class="mf">5.</span><span class="x">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>5-element Vector{Float64}:
 0.058823529411764705
 0.058823529411764705
 0.29411764705882354
 0.29411764705882354
 0.29411764705882354
</code></pre></div></div>

<p>Next, we write a generative function that applies this heuristic for both the
x-coordinate and y-coordinate, and samples the destination coordinates at
addresses <code class="highlighter-rouge">:dest_x</code> and <code class="highlighter-rouge">:dest_y</code>.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@gen</span> <span class="k">function</span><span class="nf"> custom_dest_proposal</span><span class="x">(</span><span class="n">measurements</span><span class="o">::</span><span class="n">Vector</span><span class="x">{</span><span class="n">Point</span><span class="x">},</span> <span class="n">scene</span><span class="o">::</span><span class="n">Scene</span><span class="x">)</span>

    <span class="n">score_high</span> <span class="o">=</span> <span class="mf">5.</span>
    
    <span class="n">x_first</span> <span class="o">=</span> <span class="n">measurements</span><span class="x">[</span><span class="mi">1</span><span class="x">]</span><span class="o">.</span><span class="n">x</span>
    <span class="n">x_last</span> <span class="o">=</span> <span class="n">measurements</span><span class="x">[</span><span class="k">end</span><span class="x">]</span><span class="o">.</span><span class="n">x</span>
    <span class="n">y_first</span> <span class="o">=</span> <span class="n">measurements</span><span class="x">[</span><span class="mi">1</span><span class="x">]</span><span class="o">.</span><span class="n">y</span>
    <span class="n">y_last</span> <span class="o">=</span> <span class="n">measurements</span><span class="x">[</span><span class="k">end</span><span class="x">]</span><span class="o">.</span><span class="n">y</span>
    
    <span class="c"># sample dest_x</span>
    <span class="n">x_probs</span> <span class="o">=</span> <span class="n">compute_bin_probs</span><span class="x">(</span><span class="n">num_x_bins</span><span class="x">,</span> <span class="n">scene</span><span class="o">.</span><span class="n">xmin</span><span class="x">,</span> <span class="n">scene</span><span class="o">.</span><span class="n">xmax</span><span class="x">,</span> <span class="n">x_first</span><span class="x">,</span> <span class="n">x_last</span><span class="x">,</span> <span class="n">score_high</span><span class="x">)</span>
    <span class="n">x_bounds</span> <span class="o">=</span> <span class="n">collect</span><span class="x">(</span><span class="n">range</span><span class="x">(</span><span class="n">scene</span><span class="o">.</span><span class="n">xmin</span><span class="x">,</span> <span class="n">stop</span><span class="o">=</span><span class="n">scene</span><span class="o">.</span><span class="n">xmax</span><span class="x">,</span> <span class="n">length</span><span class="o">=</span><span class="n">num_x_bins</span><span class="o">+</span><span class="mi">1</span><span class="x">))</span>
    <span class="n">dest_x</span> <span class="o">~</span> <span class="n">piecewise_uniform</span><span class="x">(</span><span class="n">x_bounds</span><span class="x">,</span> <span class="n">x_probs</span><span class="x">)</span>
    
    <span class="c"># sample dest_y</span>
    <span class="n">y_probs</span> <span class="o">=</span> <span class="n">compute_bin_probs</span><span class="x">(</span><span class="n">num_y_bins</span><span class="x">,</span> <span class="n">scene</span><span class="o">.</span><span class="n">ymin</span><span class="x">,</span> <span class="n">scene</span><span class="o">.</span><span class="n">ymax</span><span class="x">,</span> <span class="n">y_first</span><span class="x">,</span> <span class="n">y_last</span><span class="x">,</span> <span class="n">score_high</span><span class="x">)</span>
    <span class="n">y_bounds</span> <span class="o">=</span> <span class="n">collect</span><span class="x">(</span><span class="n">range</span><span class="x">(</span><span class="n">scene</span><span class="o">.</span><span class="n">ymin</span><span class="x">,</span> <span class="n">stop</span><span class="o">=</span><span class="n">scene</span><span class="o">.</span><span class="n">ymax</span><span class="x">,</span> <span class="n">length</span><span class="o">=</span><span class="n">num_y_bins</span><span class="o">+</span><span class="mi">1</span><span class="x">))</span>
    <span class="n">dest_y</span> <span class="o">~</span> <span class="n">piecewise_uniform</span><span class="x">(</span><span class="n">y_bounds</span><span class="x">,</span> <span class="n">y_probs</span><span class="x">)</span>
    
    <span class="k">return</span> <span class="n">nothing</span>
<span class="k">end</span><span class="x">;</span>
</code></pre></div></div>

<p>We can propose values of random choices from the proposal function using
<a href="https://probcomp.github.io/Gen/dev/ref/gfi/#Gen.propose"><code class="highlighter-rouge">Gen.propose</code></a>.
This method returns the choices, as well as some other information, which we
won’t need for our purposes. For now, you can think of <code class="highlighter-rouge">Gen.propose</code> as
similar to <code class="highlighter-rouge">Gen.generate</code> except that it does not produce a full execution
trace (only the choices), and it does not accept constraints. We can see the
random choices for one run of the proposal on our data set:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="x">(</span><span class="n">proposed_choices</span><span class="x">,</span> <span class="n">_</span><span class="x">,</span> <span class="n">_</span><span class="x">)</span> <span class="o">=</span> <span class="n">Gen</span><span class="o">.</span><span class="n">propose</span><span class="x">(</span><span class="n">custom_dest_proposal</span><span class="x">,</span> <span class="x">(</span><span class="n">measurements</span><span class="x">,</span> <span class="n">scene</span><span class="x">))</span>
<span class="n">proposed_choices</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>│
├── :dest_y : 0.5004991033166655
│
└── :dest_x : 0.9394799919113345
</code></pre></div></div>

<p>The function below runs the proposal 1000 times. For each run, it generates a
trace of the model where the <code class="highlighter-rouge">:dest_x</code> and <code class="highlighter-rouge">:dest_y</code> choices are constrained
to the proposed values, and then visualizes the resulting traces. We make the
proposal a parameter of the function because we will be visualizing the
output distribution of various proposals later in the notebook.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span><span class="nf"> visualize_custom_destination_proposal</span><span class="x">(</span><span class="n">measurements</span><span class="x">,</span> <span class="n">start</span><span class="x">,</span> <span class="n">dest_proposal</span><span class="x">;</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">100</span><span class="x">)</span>
    <span class="n">visualize</span><span class="x">()</span> <span class="n">do</span> 
        <span class="k">for</span> <span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="x">:</span><span class="n">num_samples</span>
            <span class="x">(</span><span class="n">proposed_choices</span><span class="x">,</span> <span class="n">_</span><span class="x">)</span> <span class="o">=</span> <span class="n">Gen</span><span class="o">.</span><span class="n">propose</span><span class="x">(</span><span class="n">dest_proposal</span><span class="x">,</span> <span class="x">(</span><span class="n">measurements</span><span class="x">,</span> <span class="n">scene</span><span class="x">))</span>
            <span class="n">constraints</span> <span class="o">=</span> <span class="n">choicemap</span><span class="x">(</span><span class="n">proposed_choices</span><span class="x">)</span>
            <span class="n">constraints</span><span class="x">[:</span><span class="n">start_x</span><span class="x">]</span> <span class="o">=</span> <span class="n">start</span><span class="o">.</span><span class="n">x</span>
            <span class="n">constraints</span><span class="x">[:</span><span class="n">start_y</span><span class="x">]</span> <span class="o">=</span> <span class="n">start</span><span class="o">.</span><span class="n">y</span>
            <span class="x">(</span><span class="n">trace</span><span class="x">,</span> <span class="n">_</span><span class="x">)</span> <span class="o">=</span> <span class="n">Gen</span><span class="o">.</span><span class="n">generate</span><span class="x">(</span><span class="n">agent_model</span><span class="x">,</span> <span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">dt</span><span class="x">,</span> <span class="n">num_ticks</span><span class="x">,</span> <span class="n">planner_params</span><span class="x">),</span> <span class="n">constraints</span><span class="x">)</span>
            <span class="n">draw_dest</span><span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">Point</span><span class="x">(</span><span class="n">trace</span><span class="x">[:</span><span class="n">dest_x</span><span class="x">],</span> <span class="n">trace</span><span class="x">[:</span><span class="n">dest_y</span><span class="x">]))</span>
        <span class="k">end</span>
        <span class="n">draw_scene</span><span class="x">(</span><span class="n">scene</span><span class="x">)</span>
        <span class="n">draw_start</span><span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">start</span><span class="x">)</span>
        <span class="n">draw_measurements</span><span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">measurements</span><span class="x">)</span>
    <span class="k">end</span>
<span class="k">end</span><span class="x">;</span>
</code></pre></div></div>

<p>Let’s visualize the output distribution of <code class="highlighter-rouge">custom_dest_proposal</code> for our
data set:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">visualize_custom_destination_proposal</span><span class="x">(</span><span class="n">measurements</span><span class="x">,</span> <span class="n">start</span><span class="x">,</span> <span class="n">custom_dest_proposal</span><span class="x">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1000</span><span class="x">)</span>
</code></pre></div></div>

<p><img src="output_96_0.png" alt="png" /></p>

<p>We see that the proposal distribution indeed samples destinations in the top
half of the scene with higher probability than destinations in the bottom
half.</p>

<p>Alone, this is just a heuristic. But we can use it as a proposal for importance sampling, turning it into an asymptotically valid Bayesian inference algorithm. Alternatively, we can view it as a tool for speeding up our naive importance sampler, by focusing computation on regions of the space that are more likely.</p>

<h2 id="3-using-a-data-driven-proposal-within-importance-sampling-">3. Using a data-driven proposal within importance sampling <a name="using"></a></h2>

<p>We now use our data-driven proposal within an inference algorithm. There is a
second variant of
<a href="https://probcomp.github.io/Gen/dev/ref/importance/#Gen.importance_resampling"><code class="highlighter-rouge">Gen.importance_resampling</code></a>
that accepts a generative function representing a custom proposal. This
proposal generative function makes traced random choices at the addresses of
a subset of the unobserved random choices made by the generative model. In
our case, these addresses are <code class="highlighter-rouge">:dest_x</code> and <code class="highlighter-rouge">:dest_y</code>.</p>

<hr />

<h3 id="exercise-5">Exercise</h3>

<p>Implement an inference program that uses this second variant of importance resampling.</p>

<p>Because we will experiment with different data-driven proposals, we make the
proposal into an agument of our inference program. We assume that the
proposal accepts arguments <code class="highlighter-rouge">(measurements, scene)</code>.</p>

<p>This time, use only 5 importance samples (<code class="highlighter-rouge">amt_computation</code>). You can run
<code class="highlighter-rouge">?Gen.importance_resampling</code> or check out the
<a href="https://probcomp.github.io/Gen/dev/ref/inference/#Importance-Sampling-1">documentation</a>
to understand how to supply the arguments to invoke this second version of of
importance resampling.</p>

<p>We have provided some starter code.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span><span class="nf"> do_inference_data_driven</span><span class="x">(</span>
        <span class="n">dest_proposal</span><span class="o">::</span><span class="n">GenerativeFunction</span><span class="x">,</span>
        <span class="n">scene</span><span class="o">::</span><span class="n">Scene</span><span class="x">,</span> <span class="n">dt</span><span class="o">::</span><span class="kt">Float64</span><span class="x">,</span>
        <span class="n">num_ticks</span><span class="o">::</span><span class="kt">Int</span><span class="x">,</span> <span class="n">planner_params</span><span class="o">::</span><span class="n">PlannerParams</span><span class="x">,</span>
        <span class="n">start</span><span class="o">::</span><span class="n">Point</span><span class="x">,</span> <span class="n">measurements</span><span class="o">::</span><span class="n">Vector</span><span class="x">{</span><span class="n">Point</span><span class="x">},</span> 
        <span class="n">amount_of_computation</span><span class="o">::</span><span class="kt">Int</span><span class="x">)</span>
    
    <span class="n">observations</span> <span class="o">=</span> <span class="n">Gen</span><span class="o">.</span><span class="n">choicemap</span><span class="x">((:</span><span class="n">start_x</span><span class="x">,</span> <span class="n">start</span><span class="o">.</span><span class="n">x</span><span class="x">),</span> <span class="x">(:</span><span class="n">start_y</span><span class="x">,</span> <span class="n">start</span><span class="o">.</span><span class="n">y</span><span class="x">))</span>
    <span class="k">for</span> <span class="x">(</span><span class="n">i</span><span class="x">,</span> <span class="n">m</span><span class="x">)</span> <span class="k">in</span> <span class="n">enumerate</span><span class="x">(</span><span class="n">measurements</span><span class="x">)</span>
        <span class="n">observations</span><span class="x">[:</span><span class="n">meas</span> <span class="o">=&gt;</span> <span class="x">(</span><span class="n">i</span><span class="x">,</span> <span class="x">:</span><span class="n">x</span><span class="x">)]</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">x</span>
        <span class="n">observations</span><span class="x">[:</span><span class="n">meas</span> <span class="o">=&gt;</span> <span class="x">(</span><span class="n">i</span><span class="x">,</span> <span class="x">:</span><span class="n">y</span><span class="x">)]</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">y</span>
    <span class="k">end</span>
    
    <span class="c"># &lt; put your code here&gt;</span>
    
    <span class="k">return</span> <span class="n">trace</span>
<span class="k">end</span><span class="x">;</span>

<span class="k">function</span><span class="nf"> visualize_data_driven_inference</span><span class="x">(</span><span class="n">measurements</span><span class="x">,</span> <span class="n">scene</span><span class="x">,</span> <span class="n">start</span><span class="x">,</span> <span class="n">proposal</span><span class="x">;</span> <span class="n">amt_computation</span><span class="o">=</span><span class="mi">50</span><span class="x">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">1000</span><span class="x">)</span>
    <span class="n">visualize</span><span class="x">()</span> <span class="n">do</span> 
      <span class="k">for</span> <span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="x">:</span><span class="n">samples</span>
          <span class="n">trace</span> <span class="o">=</span> <span class="n">do_inference_data_driven</span><span class="x">(</span><span class="n">proposal</span><span class="x">,</span> 
              <span class="n">scene</span><span class="x">,</span> <span class="n">dt</span><span class="x">,</span> <span class="n">num_ticks</span><span class="x">,</span> <span class="n">planner_params</span><span class="x">,</span> <span class="n">start</span><span class="x">,</span> <span class="n">measurements</span><span class="x">,</span> <span class="n">amt_computation</span><span class="x">)</span>
          <span class="n">draw_trace</span><span class="x">(</span><span class="n">trace</span><span class="x">;</span> <span class="n">draw_path</span><span class="o">=</span><span class="n">false</span><span class="x">)</span>
      <span class="k">end</span>
    <span class="k">end</span>
<span class="k">end</span><span class="x">;</span>
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">visualize_data_driven_inference</span><span class="x">(</span><span class="n">measurements</span><span class="x">,</span> <span class="n">scene</span><span class="x">,</span> <span class="n">start</span><span class="x">,</span> <span class="n">custom_dest_proposal</span><span class="x">;</span> <span class="n">amt_computation</span><span class="o">=</span><span class="mi">5</span><span class="x">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">1000</span><span class="x">)</span>
</code></pre></div></div>

<p><img src="output_104_0.png" alt="png" /></p>

<p>The code executes much more quickly than before, because we are only taking five proposal samples to generate each.</p>

<p>We compare this to the original algorithm that used the default proposal, for
the same “amount of computation” of 5.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">visualize_inference</span><span class="x">(</span><span class="n">measurements</span><span class="x">,</span> <span class="n">scene</span><span class="x">,</span> <span class="n">start</span><span class="x">,</span> <span class="n">computation_amt</span><span class="o">=</span><span class="mi">5</span><span class="x">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">1000</span><span class="x">)</span>
</code></pre></div></div>

<p><img src="output_107_0.png" alt="png" /></p>

<p>We should see that the results are somewhat more accurate using the
data-driven proposal.  In particular, there is less probability mass in the
lower left corner when using the data-driven proposal.</p>

<hr />

<!-- # BEGIN ANSWER KEY 2A.5

function do_inference_data_driven(
        dest_proposal::GenerativeFunction,
        scene::Scene, dt::Float64,
        num_ticks::Int, planner_params::PlannerParams,
        start::Point, measurements::Vector{Point}, 
        amount_of_computation::Int)
    
    observations = Gen.choicemap((:start_x, start.x), (:start_y, start.y))
    for (i, m) in enumerate(measurements)
        observations[:meas => (i, :x)] = m.x
        observations[:meas => (i, :y)] = m.y
    end
    
    # invoke the variant of importance_resampling 
    # that accepts a custom proposal (dest_proposal).
    # the arguments to the custom proposal are (measurements, scene)
    (trace, _) = Gen.importance_resampling(agent_model, (scene, dt, num_ticks, planner_params), observations, 
        dest_proposal, (measurements, scene), amount_of_computation)
    
    return trace
end;

function visualize_data_driven_inference(measurements, scene, start, proposal; amt_computation=50, samples=1000)
    visualize() do 
      for i=1:samples
          trace = do_inference_data_driven(proposal, 
              scene, dt, num_ticks, planner_params, start, measurements, amt_computation)
          draw_dest(scene, Point(trace[:dest_x], trace[:dest_y]))
      end
        draw_scene(scene)
        draw_start(scene, start)
        draw_measurements(scene, measurements)
    end
end;

# END ANSWER KEY -->

<h2 id="4-training-the-parameters-of-a-data-driven-proposal-">4. Training the parameters of a data-driven proposal <a name="training"></a></h2>

<p>Our choice of the <code class="highlighter-rouge">score_high</code> value of 5. was somewhat arbitrary. To use
more informed value, we can make <code class="highlighter-rouge">score_high</code> into a <a href="https://www.gen.dev/dev/ref/gfi/#Trainable-parameters-1"><em>trainable
parameter</em></a>
of the generative function. Below, we write a new version of the proposal
function that makes <code class="highlighter-rouge">score_high</code> trainable. However, the optimization
algorithms we will use for training work best with <em>unconstrained</em> parameters
(parameters that can take any value on the real line), but <code class="highlighter-rouge">score_high</code> must
be positive. Therefore, we introduce an unconstrained trainable parameter
mamed <code class="highlighter-rouge">log_score_high</code>, and use <code class="highlighter-rouge">exp()</code> to ensure that <code class="highlighter-rouge">score_high</code> is
positive:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@gen</span> <span class="k">function</span><span class="nf"> custom_dest_proposal_trainable</span><span class="x">(</span><span class="n">measurements</span><span class="o">::</span><span class="n">Vector</span><span class="x">{</span><span class="n">Point</span><span class="x">},</span> <span class="n">scene</span><span class="o">::</span><span class="n">Scene</span><span class="x">)</span>

    <span class="nd">@param</span> <span class="n">log_score_high</span><span class="o">::</span><span class="kt">Float64</span>
    
    <span class="n">x_first</span> <span class="o">=</span> <span class="n">measurements</span><span class="x">[</span><span class="mi">1</span><span class="x">]</span><span class="o">.</span><span class="n">x</span>
    <span class="n">x_last</span> <span class="o">=</span> <span class="n">measurements</span><span class="x">[</span><span class="k">end</span><span class="x">]</span><span class="o">.</span><span class="n">x</span>
    <span class="n">y_first</span> <span class="o">=</span> <span class="n">measurements</span><span class="x">[</span><span class="mi">1</span><span class="x">]</span><span class="o">.</span><span class="n">y</span>
    <span class="n">y_last</span> <span class="o">=</span> <span class="n">measurements</span><span class="x">[</span><span class="k">end</span><span class="x">]</span><span class="o">.</span><span class="n">y</span>
    
    <span class="c"># sample dest_x</span>
    <span class="n">x_probs</span> <span class="o">=</span> <span class="n">compute_bin_probs</span><span class="x">(</span><span class="n">num_x_bins</span><span class="x">,</span> <span class="n">scene</span><span class="o">.</span><span class="n">xmin</span><span class="x">,</span> <span class="n">scene</span><span class="o">.</span><span class="n">xmax</span><span class="x">,</span> <span class="n">x_first</span><span class="x">,</span> <span class="n">x_last</span><span class="x">,</span> <span class="n">exp</span><span class="x">(</span><span class="n">log_score_high</span><span class="x">))</span>
    <span class="n">x_bounds</span> <span class="o">=</span> <span class="n">collect</span><span class="x">(</span><span class="n">range</span><span class="x">(</span><span class="n">scene</span><span class="o">.</span><span class="n">xmin</span><span class="x">,</span> <span class="n">stop</span><span class="o">=</span><span class="n">scene</span><span class="o">.</span><span class="n">xmax</span><span class="x">,</span> <span class="n">length</span><span class="o">=</span><span class="n">num_x_bins</span><span class="o">+</span><span class="mi">1</span><span class="x">))</span>
    <span class="n">dest_x</span> <span class="o">~</span> <span class="n">piecewise_uniform</span><span class="x">(</span><span class="n">x_bounds</span><span class="x">,</span> <span class="n">x_probs</span><span class="x">)</span>
    
    <span class="c"># sample dest_y</span>
    <span class="n">y_probs</span> <span class="o">=</span> <span class="n">compute_bin_probs</span><span class="x">(</span><span class="n">num_y_bins</span><span class="x">,</span> <span class="n">scene</span><span class="o">.</span><span class="n">ymin</span><span class="x">,</span> <span class="n">scene</span><span class="o">.</span><span class="n">ymax</span><span class="x">,</span> <span class="n">y_first</span><span class="x">,</span> <span class="n">y_last</span><span class="x">,</span> <span class="n">exp</span><span class="x">(</span><span class="n">log_score_high</span><span class="x">))</span>
    <span class="n">y_bounds</span> <span class="o">=</span> <span class="n">collect</span><span class="x">(</span><span class="n">range</span><span class="x">(</span><span class="n">scene</span><span class="o">.</span><span class="n">ymin</span><span class="x">,</span> <span class="n">stop</span><span class="o">=</span><span class="n">scene</span><span class="o">.</span><span class="n">ymax</span><span class="x">,</span> <span class="n">length</span><span class="o">=</span><span class="n">num_y_bins</span><span class="o">+</span><span class="mi">1</span><span class="x">))</span>
    <span class="n">dest_y</span> <span class="o">~</span> <span class="n">piecewise_uniform</span><span class="x">(</span><span class="n">y_bounds</span><span class="x">,</span> <span class="n">y_probs</span><span class="x">)</span>
    
    <span class="k">return</span> <span class="n">nothing</span>
<span class="k">end</span><span class="x">;</span>
</code></pre></div></div>

<p>We initialize the value of <code class="highlighter-rouge">score_high</code> to 1. For this value, our custom
proposal gives a uniform distribution, and is the same as the default
proposal.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Gen</span><span class="o">.</span><span class="n">init_param!</span><span class="x">(</span><span class="n">custom_dest_proposal_trainable</span><span class="x">,</span> <span class="x">:</span><span class="n">log_score_high</span><span class="x">,</span> <span class="mf">0.</span><span class="x">);</span>
</code></pre></div></div>

<p>Let’s visualize the proposed distribution prior to training to confirm that
it is a uniform distribution.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">visualize_custom_destination_proposal</span><span class="x">(</span><span class="n">measurements</span><span class="x">,</span> <span class="n">start</span><span class="x">,</span> <span class="n">custom_dest_proposal_trainable</span><span class="x">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1000</span><span class="x">)</span>
</code></pre></div></div>

<p><img src="output_116_0.png" alt="png" /></p>

<p>Now, we train the generative function. First, we will require a
data-generator that generates the training data. The data-generator is a
function of no arguments that returns a tuple of the form <code class="highlighter-rouge">(inputs, constraints)</code>. 
The <code class="highlighter-rouge">inputs</code> are the arguments to the generative function
being trained, and the <code class="highlighter-rouge">constraints</code> contains the desired values of random
choices made by the function for those arguments. For the training
distribution, we will use the distribution induced by the generative model
(<code class="highlighter-rouge">agent_model</code>), restricted to cases where planning actually succeeded. When
planning failed, the agent just stays at the same location for all time, and
we won’t worry about tuning our proposal for that case. The training
procedure will attempt to maximize the expected conditional log probablity
(density) that the proposal function generates the constrained values,
when run on the arguments. 
Note that this is an <em>average case</em> objective function — the resulting proposal 
distribution may perform better on some data sets than others.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span><span class="nf"> data_generator</span><span class="x">()</span>
    
    <span class="c"># since these names are used in the global scope, explicitly declare it</span>
    <span class="c"># local to avoid overwriting the global variable</span>
    <span class="kd">local</span> <span class="n">measurements</span>
    <span class="kd">local</span> <span class="n">choices</span>
    
    <span class="c"># obtain an execution of the model where planning succeeded</span>
    <span class="n">done</span> <span class="o">=</span> <span class="n">false</span>
    <span class="k">while</span> <span class="o">!</span><span class="n">done</span>
        <span class="x">(</span><span class="n">choices</span><span class="x">,</span> <span class="n">_</span><span class="x">,</span> <span class="n">retval</span><span class="x">)</span> <span class="o">=</span> <span class="n">Gen</span><span class="o">.</span><span class="n">propose</span><span class="x">(</span><span class="n">agent_model</span><span class="x">,</span> <span class="x">(</span><span class="n">scene</span><span class="x">,</span> <span class="n">dt</span><span class="x">,</span> <span class="n">num_ticks</span><span class="x">,</span> <span class="n">planner_params</span><span class="x">))</span>
        <span class="x">(</span><span class="n">planning_failed</span><span class="x">,</span> <span class="n">maybe_path</span><span class="x">)</span> <span class="o">=</span> <span class="n">retval</span>       
        <span class="n">done</span> <span class="o">=</span> <span class="o">!</span><span class="n">planning_failed</span>
    <span class="k">end</span>

    <span class="c"># construct arguments to the proposal function being trained</span>
    <span class="n">measurements</span> <span class="o">=</span> <span class="x">[</span><span class="n">Point</span><span class="x">(</span><span class="n">choices</span><span class="x">[:</span><span class="n">meas</span> <span class="o">=&gt;</span> <span class="x">(</span><span class="n">i</span><span class="x">,</span> <span class="x">:</span><span class="n">x</span><span class="x">)],</span> <span class="n">choices</span><span class="x">[:</span><span class="n">meas</span> <span class="o">=&gt;</span> <span class="x">(</span><span class="n">i</span><span class="x">,</span> <span class="x">:</span><span class="n">y</span><span class="x">)])</span> <span class="k">for</span> <span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="x">:</span><span class="n">num_ticks</span><span class="x">]</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="x">(</span><span class="n">measurements</span><span class="x">,</span> <span class="n">scene</span><span class="x">)</span>
    
    <span class="c"># construct constraints for the proposal function being trained</span>
    <span class="n">constraints</span> <span class="o">=</span> <span class="n">Gen</span><span class="o">.</span><span class="n">choicemap</span><span class="x">()</span>
    <span class="n">constraints</span><span class="x">[:</span><span class="n">dest_x</span><span class="x">]</span> <span class="o">=</span> <span class="n">choices</span><span class="x">[:</span><span class="n">dest_x</span><span class="x">]</span>
    <span class="n">constraints</span><span class="x">[:</span><span class="n">dest_y</span><span class="x">]</span> <span class="o">=</span> <span class="n">choices</span><span class="x">[:</span><span class="n">dest_y</span><span class="x">]</span>
    
    <span class="k">return</span> <span class="x">(</span><span class="n">inputs</span><span class="x">,</span> <span class="n">constraints</span><span class="x">)</span>
<span class="k">end</span><span class="x">;</span>
</code></pre></div></div>

<p>Next, we choose type of optimization algorithm we will use for training. Gen
supports a set of gradient-based optimization algorithms (see <a href="https://www.gen.dev/dev/ref/parameter_optimization/#Optimizing-Trainable-Parameters-1">Optimizing
Trainable
Parameters</a>).
Here we will use gradient descent with a fixed step size of 0.001.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">update</span> <span class="o">=</span> <span class="n">Gen</span><span class="o">.</span><span class="n">ParamUpdate</span><span class="x">(</span><span class="n">Gen</span><span class="o">.</span><span class="n">FixedStepGradientDescent</span><span class="x">(</span><span class="mf">0.001</span><span class="x">),</span> <span class="n">custom_dest_proposal_trainable</span><span class="x">);</span>
</code></pre></div></div>

<p>Finally, we use the
<a href="https://probcomp.github.io/Gen/dev/ref/inference/#Gen.train!"><code class="highlighter-rouge">Gen.train!</code></a>
method to actually do the training.</p>

<p>For each epoch, <code class="highlighter-rouge">Gen.train!</code> makes <code class="highlighter-rouge">epoch_size</code> calls to the data-generator
to construct a batch of training data for that epoch. Then, it iteratively
selects <code class="highlighter-rouge">num_minibatch</code> subsets of the epoch training data, each of size
<code class="highlighter-rouge">100</code>, and applies the update once per minibatch. At the end of the epoch, it
generates another batch of evaluation data (of size <code class="highlighter-rouge">evaluation_size</code>) which
it uses to estimate the objective function (the expected conditional log
likelihood under the data-generating distribution).</p>

<p>Here, we are running 200 gradient-descent updates, where each update is using
a gradient estimate obtained from 100 training examples. The method prints
the estimate of the objective function after each epoch.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@time</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">Gen</span><span class="o">.</span><span class="n">train!</span><span class="x">(</span><span class="n">custom_dest_proposal_trainable</span><span class="x">,</span> <span class="n">data_generator</span><span class="x">,</span> <span class="n">update</span><span class="x">,</span>
    <span class="n">num_epoch</span><span class="o">=</span><span class="mi">200</span><span class="x">,</span> <span class="n">epoch_size</span><span class="o">=</span><span class="mi">100</span><span class="x">,</span> <span class="n">num_minibatch</span><span class="o">=</span><span class="mi">1</span><span class="x">,</span> <span class="n">minibatch_size</span><span class="o">=</span><span class="mi">100</span><span class="x">,</span> <span class="n">evaluation_size</span><span class="o">=</span><span class="mi">100</span><span class="x">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">true</span><span class="x">);</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>epoch 1: generating 100 training examples...
epoch 1: training using 1 minibatches of size 100...
epoch 1: evaluating on 100 examples...
epoch 1: est. objective value: 0.05785100924257531
epoch 2: generating 100 training examples...
epoch 2: training using 1 minibatches of size 100...
epoch 2: evaluating on 100 examples...
epoch 2: est. objective value: 0.10854499533252521
epoch 3: generating 100 training examples...
epoch 3: training using 1 minibatches of size 100...
epoch 3: evaluating on 100 examples...
epoch 3: est. objective value: 0.17802119782086115
epoch 4: generating 100 training examples...
epoch 4: training using 1 minibatches of size 100...
epoch 4: evaluating on 100 examples...
epoch 4: est. objective value: 0.16943365364376994
epoch 5: generating 100 training examples...
epoch 5: training using 1 minibatches of size 100...
epoch 5: evaluating on 100 examples...
epoch 5: est. objective value: 0.25224010092178895
epoch 6: generating 100 training examples...
epoch 6: training using 1 minibatches of size 100...
epoch 6: evaluating on 100 examples...
epoch 6: est. objective value: 0.2600018362541301
epoch 7: generating 100 training examples...
epoch 7: training using 1 minibatches of size 100...
epoch 7: evaluating on 100 examples...
epoch 7: est. objective value: 0.28857266800250997
epoch 8: generating 100 training examples...
epoch 8: training using 1 minibatches of size 100...
epoch 8: evaluating on 100 examples...
epoch 8: est. objective value: 0.3265979863218243
epoch 9: generating 100 training examples...
epoch 9: training using 1 minibatches of size 100...
epoch 9: evaluating on 100 examples...
epoch 9: est. objective value: 0.3470483151341039
epoch 10: generating 100 training examples...
epoch 10: training using 1 minibatches of size 100...
epoch 10: evaluating on 100 examples...
epoch 10: est. objective value: 0.3859753723585414
epoch 11: generating 100 training examples...
epoch 11: training using 1 minibatches of size 100...
epoch 11: evaluating on 100 examples...
epoch 11: est. objective value: 0.4284073922825604
epoch 12: generating 100 training examples...
epoch 12: training using 1 minibatches of size 100...
epoch 12: evaluating on 100 examples...
epoch 12: est. objective value: 0.4301755939248777
epoch 13: generating 100 training examples...
epoch 13: training using 1 minibatches of size 100...
epoch 13: evaluating on 100 examples...
epoch 13: est. objective value: 0.4228622975312839
epoch 14: generating 100 training examples...
epoch 14: training using 1 minibatches of size 100...
epoch 14: evaluating on 100 examples...
epoch 14: est. objective value: 0.4654641163722421
epoch 15: generating 100 training examples...
epoch 15: training using 1 minibatches of size 100...
epoch 15: evaluating on 100 examples...
epoch 15: est. objective value: 0.5097866760735316
epoch 16: generating 100 training examples...
epoch 16: training using 1 minibatches of size 100...
epoch 16: evaluating on 100 examples...
epoch 16: est. objective value: 0.4837946365147511
epoch 17: generating 100 training examples...
epoch 17: training using 1 minibatches of size 100...
epoch 17: evaluating on 100 examples...
epoch 17: est. objective value: 0.5693676943516194
epoch 18: generating 100 training examples...
epoch 18: training using 1 minibatches of size 100...
epoch 18: evaluating on 100 examples...
epoch 18: est. objective value: 0.5120577411940124
epoch 19: generating 100 training examples...
epoch 19: training using 1 minibatches of size 100...
epoch 19: evaluating on 100 examples...
epoch 19: est. objective value: 0.5594086404774237
epoch 20: generating 100 training examples...
epoch 20: training using 1 minibatches of size 100...
epoch 20: evaluating on 100 examples...
epoch 20: est. objective value: 0.7128739625593462
epoch 21: generating 100 training examples...
epoch 21: training using 1 minibatches of size 100...
epoch 21: evaluating on 100 examples...
epoch 21: est. objective value: 0.5839555616850383
epoch 22: generating 100 training examples...
epoch 22: training using 1 minibatches of size 100...
epoch 22: evaluating on 100 examples...
epoch 22: est. objective value: 0.6361204786166387
epoch 23: generating 100 training examples...
epoch 23: training using 1 minibatches of size 100...
epoch 23: evaluating on 100 examples...
epoch 23: est. objective value: 0.514493812801509
epoch 24: generating 100 training examples...
epoch 24: training using 1 minibatches of size 100...
epoch 24: evaluating on 100 examples...
epoch 24: est. objective value: 0.5521665778988273
epoch 25: generating 100 training examples...
epoch 25: training using 1 minibatches of size 100...
epoch 25: evaluating on 100 examples...
epoch 25: est. objective value: 0.722149384138051
epoch 26: generating 100 training examples...
epoch 26: training using 1 minibatches of size 100...
epoch 26: evaluating on 100 examples...
epoch 26: est. objective value: 0.7179368358857857
epoch 27: generating 100 training examples...
epoch 27: training using 1 minibatches of size 100...
epoch 27: evaluating on 100 examples...
epoch 27: est. objective value: 0.6385972247305424
epoch 28: generating 100 training examples...
epoch 28: training using 1 minibatches of size 100...
epoch 28: evaluating on 100 examples...
epoch 28: est. objective value: 0.5362090752152102
epoch 29: generating 100 training examples...
epoch 29: training using 1 minibatches of size 100...
epoch 29: evaluating on 100 examples...
epoch 29: est. objective value: 0.7187939426253733
epoch 30: generating 100 training examples...
epoch 30: training using 1 minibatches of size 100...
epoch 30: evaluating on 100 examples...
epoch 30: est. objective value: 0.6120728123723247
epoch 31: generating 100 training examples...
epoch 31: training using 1 minibatches of size 100...
epoch 31: evaluating on 100 examples...
epoch 31: est. objective value: 0.6399747242372278
epoch 32: generating 100 training examples...
epoch 32: training using 1 minibatches of size 100...
epoch 32: evaluating on 100 examples...
epoch 32: est. objective value: 0.6667764108094414
epoch 33: generating 100 training examples...
epoch 33: training using 1 minibatches of size 100...
epoch 33: evaluating on 100 examples...
epoch 33: est. objective value: 0.6060454108306579
epoch 34: generating 100 training examples...
epoch 34: training using 1 minibatches of size 100...
epoch 34: evaluating on 100 examples...
epoch 34: est. objective value: 0.6993126960011823
epoch 35: generating 100 training examples...
epoch 35: training using 1 minibatches of size 100...
epoch 35: evaluating on 100 examples...
epoch 35: est. objective value: 0.5868024946619532
epoch 36: generating 100 training examples...
epoch 36: training using 1 minibatches of size 100...
epoch 36: evaluating on 100 examples...
epoch 36: est. objective value: 0.7397394832944163
epoch 37: generating 100 training examples...
epoch 37: training using 1 minibatches of size 100...
epoch 37: evaluating on 100 examples...
epoch 37: est. objective value: 0.6484161821263931
epoch 38: generating 100 training examples...
epoch 38: training using 1 minibatches of size 100...
epoch 38: evaluating on 100 examples...
epoch 38: est. objective value: 0.633192485639994
epoch 39: generating 100 training examples...
epoch 39: training using 1 minibatches of size 100...
epoch 39: evaluating on 100 examples...
epoch 39: est. objective value: 0.7092043526263805
epoch 40: generating 100 training examples...
epoch 40: training using 1 minibatches of size 100...
epoch 40: evaluating on 100 examples...
epoch 40: est. objective value: 0.7226425143089503
epoch 41: generating 100 training examples...
epoch 41: training using 1 minibatches of size 100...
epoch 41: evaluating on 100 examples...
epoch 41: est. objective value: 0.8289362809357658
epoch 42: generating 100 training examples...
epoch 42: training using 1 minibatches of size 100...
epoch 42: evaluating on 100 examples...
epoch 42: est. objective value: 0.6238745931575056
epoch 43: generating 100 training examples...
epoch 43: training using 1 minibatches of size 100...
epoch 43: evaluating on 100 examples...
epoch 43: est. objective value: 0.7835526547733975
epoch 44: generating 100 training examples...
epoch 44: training using 1 minibatches of size 100...
epoch 44: evaluating on 100 examples...
epoch 44: est. objective value: 0.7258695419527986
epoch 45: generating 100 training examples...
epoch 45: training using 1 minibatches of size 100...
epoch 45: evaluating on 100 examples...
epoch 45: est. objective value: 0.6453366841162662
epoch 46: generating 100 training examples...
epoch 46: training using 1 minibatches of size 100...
epoch 46: evaluating on 100 examples...
epoch 46: est. objective value: 0.7351976910645631
epoch 47: generating 100 training examples...
epoch 47: training using 1 minibatches of size 100...
epoch 47: evaluating on 100 examples...
epoch 47: est. objective value: 0.6362399728242216
epoch 48: generating 100 training examples...
epoch 48: training using 1 minibatches of size 100...
epoch 48: evaluating on 100 examples...
epoch 48: est. objective value: 0.673777648894192
epoch 49: generating 100 training examples...
epoch 49: training using 1 minibatches of size 100...
epoch 49: evaluating on 100 examples...
epoch 49: est. objective value: 0.7785251530543853
epoch 50: generating 100 training examples...
epoch 50: training using 1 minibatches of size 100...
epoch 50: evaluating on 100 examples...
epoch 50: est. objective value: 0.7856205637218372
epoch 51: generating 100 training examples...
epoch 51: training using 1 minibatches of size 100...
epoch 51: evaluating on 100 examples...
epoch 51: est. objective value: 0.8383660941318891
epoch 52: generating 100 training examples...
epoch 52: training using 1 minibatches of size 100...
epoch 52: evaluating on 100 examples...
epoch 52: est. objective value: 0.5975512917509169
epoch 53: generating 100 training examples...
epoch 53: training using 1 minibatches of size 100...
epoch 53: evaluating on 100 examples...
epoch 53: est. objective value: 0.6198315779945609
epoch 54: generating 100 training examples...
epoch 54: training using 1 minibatches of size 100...
epoch 54: evaluating on 100 examples...
epoch 54: est. objective value: 0.696603097343118
epoch 55: generating 100 training examples...
epoch 55: training using 1 minibatches of size 100...
epoch 55: evaluating on 100 examples...
epoch 55: est. objective value: 0.8564657930115089
epoch 56: generating 100 training examples...
epoch 56: training using 1 minibatches of size 100...
epoch 56: evaluating on 100 examples...
epoch 56: est. objective value: 0.7315561910099225
epoch 57: generating 100 training examples...
epoch 57: training using 1 minibatches of size 100...
epoch 57: evaluating on 100 examples...
epoch 57: est. objective value: 0.9261978144605725
epoch 58: generating 100 training examples...
epoch 58: training using 1 minibatches of size 100...
epoch 58: evaluating on 100 examples...
epoch 58: est. objective value: 0.6856787340956232
epoch 59: generating 100 training examples...
epoch 59: training using 1 minibatches of size 100...
epoch 59: evaluating on 100 examples...
epoch 59: est. objective value: 0.5810084958777275
epoch 60: generating 100 training examples...
epoch 60: training using 1 minibatches of size 100...
epoch 60: evaluating on 100 examples...
epoch 60: est. objective value: 0.7750850301398664
epoch 61: generating 100 training examples...
epoch 61: training using 1 minibatches of size 100...
epoch 61: evaluating on 100 examples...
epoch 61: est. objective value: 0.7070127495186178
epoch 62: generating 100 training examples...
epoch 62: training using 1 minibatches of size 100...
epoch 62: evaluating on 100 examples...
epoch 62: est. objective value: 0.8374306630993277
epoch 63: generating 100 training examples...
epoch 63: training using 1 minibatches of size 100...
epoch 63: evaluating on 100 examples...
epoch 63: est. objective value: 0.6478386026838485
epoch 64: generating 100 training examples...
epoch 64: training using 1 minibatches of size 100...
epoch 64: evaluating on 100 examples...
epoch 64: est. objective value: 0.6226332924003993
epoch 65: generating 100 training examples...
epoch 65: training using 1 minibatches of size 100...
epoch 65: evaluating on 100 examples...
epoch 65: est. objective value: 0.6949528160643271
epoch 66: generating 100 training examples...
epoch 66: training using 1 minibatches of size 100...
epoch 66: evaluating on 100 examples...
epoch 66: est. objective value: 0.7431378669138905
epoch 67: generating 100 training examples...
epoch 67: training using 1 minibatches of size 100...
epoch 67: evaluating on 100 examples...
epoch 67: est. objective value: 0.8246388766532806
epoch 68: generating 100 training examples...
epoch 68: training using 1 minibatches of size 100...
epoch 68: evaluating on 100 examples...
epoch 68: est. objective value: 0.6237102102894974
epoch 69: generating 100 training examples...
epoch 69: training using 1 minibatches of size 100...
epoch 69: evaluating on 100 examples...
epoch 69: est. objective value: 0.6496936852109243
epoch 70: generating 100 training examples...
epoch 70: training using 1 minibatches of size 100...
epoch 70: evaluating on 100 examples...
epoch 70: est. objective value: 0.7590773064951624
epoch 71: generating 100 training examples...
epoch 71: training using 1 minibatches of size 100...
epoch 71: evaluating on 100 examples...
epoch 71: est. objective value: 0.6223527848248228
epoch 72: generating 100 training examples...
epoch 72: training using 1 minibatches of size 100...
epoch 72: evaluating on 100 examples...
epoch 72: est. objective value: 0.6370460559515372
epoch 73: generating 100 training examples...
epoch 73: training using 1 minibatches of size 100...
epoch 73: evaluating on 100 examples...
epoch 73: est. objective value: 0.49744691999305024
epoch 74: generating 100 training examples...
epoch 74: training using 1 minibatches of size 100...
epoch 74: evaluating on 100 examples...
epoch 74: est. objective value: 0.5625304611117911
epoch 75: generating 100 training examples...
epoch 75: training using 1 minibatches of size 100...
epoch 75: evaluating on 100 examples...
epoch 75: est. objective value: 0.564213325723031
epoch 76: generating 100 training examples...
epoch 76: training using 1 minibatches of size 100...
epoch 76: evaluating on 100 examples...
epoch 76: est. objective value: 0.8503764397180744
epoch 77: generating 100 training examples...
epoch 77: training using 1 minibatches of size 100...
epoch 77: evaluating on 100 examples...
epoch 77: est. objective value: 0.6585473876028527
epoch 78: generating 100 training examples...
epoch 78: training using 1 minibatches of size 100...
epoch 78: evaluating on 100 examples...
epoch 78: est. objective value: 0.7931359427805479
epoch 79: generating 100 training examples...
epoch 79: training using 1 minibatches of size 100...
epoch 79: evaluating on 100 examples...
epoch 79: est. objective value: 0.7348848170447654
epoch 80: generating 100 training examples...
epoch 80: training using 1 minibatches of size 100...
epoch 80: evaluating on 100 examples...
epoch 80: est. objective value: 0.6943373984964382
epoch 81: generating 100 training examples...
epoch 81: training using 1 minibatches of size 100...
epoch 81: evaluating on 100 examples...
epoch 81: est. objective value: 0.7320228426692474
epoch 82: generating 100 training examples...
epoch 82: training using 1 minibatches of size 100...
epoch 82: evaluating on 100 examples...
epoch 82: est. objective value: 0.7951111656162692
epoch 83: generating 100 training examples...
epoch 83: training using 1 minibatches of size 100...
epoch 83: evaluating on 100 examples...
epoch 83: est. objective value: 0.7581287462361472
epoch 84: generating 100 training examples...
epoch 84: training using 1 minibatches of size 100...
epoch 84: evaluating on 100 examples...
epoch 84: est. objective value: 0.7186530055440583
epoch 85: generating 100 training examples...
epoch 85: training using 1 minibatches of size 100...
epoch 85: evaluating on 100 examples...
epoch 85: est. objective value: 0.6720805863331636
epoch 86: generating 100 training examples...
epoch 86: training using 1 minibatches of size 100...
epoch 86: evaluating on 100 examples...
epoch 86: est. objective value: 0.8873508455718452
epoch 87: generating 100 training examples...
epoch 87: training using 1 minibatches of size 100...
epoch 87: evaluating on 100 examples...
epoch 87: est. objective value: 0.6948891874010843
epoch 88: generating 100 training examples...
epoch 88: training using 1 minibatches of size 100...
epoch 88: evaluating on 100 examples...
epoch 88: est. objective value: 0.795509774949857
epoch 89: generating 100 training examples...
epoch 89: training using 1 minibatches of size 100...
epoch 89: evaluating on 100 examples...
epoch 89: est. objective value: 0.8856792471822704
epoch 90: generating 100 training examples...
epoch 90: training using 1 minibatches of size 100...
epoch 90: evaluating on 100 examples...
epoch 90: est. objective value: 0.8232994420009441
epoch 91: generating 100 training examples...
epoch 91: training using 1 minibatches of size 100...
epoch 91: evaluating on 100 examples...
epoch 91: est. objective value: 0.6251932287378781
epoch 92: generating 100 training examples...
epoch 92: training using 1 minibatches of size 100...
epoch 92: evaluating on 100 examples...
epoch 92: est. objective value: 0.7909271483856926
epoch 93: generating 100 training examples...
epoch 93: training using 1 minibatches of size 100...
epoch 93: evaluating on 100 examples...
epoch 93: est. objective value: 0.7916258268816647
epoch 94: generating 100 training examples...
epoch 94: training using 1 minibatches of size 100...
epoch 94: evaluating on 100 examples...
epoch 94: est. objective value: 0.883566763966966
epoch 95: generating 100 training examples...
epoch 95: training using 1 minibatches of size 100...
epoch 95: evaluating on 100 examples...
epoch 95: est. objective value: 0.8111689183817207
epoch 96: generating 100 training examples...
epoch 96: training using 1 minibatches of size 100...
epoch 96: evaluating on 100 examples...
epoch 96: est. objective value: 0.5651255746473081
epoch 97: generating 100 training examples...
epoch 97: training using 1 minibatches of size 100...
epoch 97: evaluating on 100 examples...
epoch 97: est. objective value: 0.8820300068363502
epoch 98: generating 100 training examples...
epoch 98: training using 1 minibatches of size 100...
epoch 98: evaluating on 100 examples...
epoch 98: est. objective value: 0.7984611694569298
epoch 99: generating 100 training examples...
epoch 99: training using 1 minibatches of size 100...
epoch 99: evaluating on 100 examples...
epoch 99: est. objective value: 0.8483539919185422
epoch 100: generating 100 training examples...
epoch 100: training using 1 minibatches of size 100...
epoch 100: evaluating on 100 examples...
epoch 100: est. objective value: 0.6518687988641542
epoch 101: generating 100 training examples...
epoch 101: training using 1 minibatches of size 100...
epoch 101: evaluating on 100 examples...
epoch 101: est. objective value: 0.6289291687677312
epoch 102: generating 100 training examples...
epoch 102: training using 1 minibatches of size 100...
epoch 102: evaluating on 100 examples...
epoch 102: est. objective value: 0.7208255799642298
epoch 103: generating 100 training examples...
epoch 103: training using 1 minibatches of size 100...
epoch 103: evaluating on 100 examples...
epoch 103: est. objective value: 0.7517458704970827
epoch 104: generating 100 training examples...
epoch 104: training using 1 minibatches of size 100...
epoch 104: evaluating on 100 examples...
epoch 104: est. objective value: 0.7758719073585226
epoch 105: generating 100 training examples...
epoch 105: training using 1 minibatches of size 100...
epoch 105: evaluating on 100 examples...
epoch 105: est. objective value: 0.7360721766966247
epoch 106: generating 100 training examples...
epoch 106: training using 1 minibatches of size 100...
epoch 106: evaluating on 100 examples...
epoch 106: est. objective value: 0.7819119555098958
epoch 107: generating 100 training examples...
epoch 107: training using 1 minibatches of size 100...
epoch 107: evaluating on 100 examples...
epoch 107: est. objective value: 0.6456167633776048
epoch 108: generating 100 training examples...
epoch 108: training using 1 minibatches of size 100...
epoch 108: evaluating on 100 examples...
epoch 108: est. objective value: 0.9117479062110171
epoch 109: generating 100 training examples...
epoch 109: training using 1 minibatches of size 100...
epoch 109: evaluating on 100 examples...
epoch 109: est. objective value: 0.8912794180953231
epoch 110: generating 100 training examples...
epoch 110: training using 1 minibatches of size 100...
epoch 110: evaluating on 100 examples...
epoch 110: est. objective value: 0.7220130455702157
epoch 111: generating 100 training examples...
epoch 111: training using 1 minibatches of size 100...
epoch 111: evaluating on 100 examples...
epoch 111: est. objective value: 0.7679238716855485
epoch 112: generating 100 training examples...
epoch 112: training using 1 minibatches of size 100...
epoch 112: evaluating on 100 examples...
epoch 112: est. objective value: 0.7123348601299996
epoch 113: generating 100 training examples...
epoch 113: training using 1 minibatches of size 100...
epoch 113: evaluating on 100 examples...
epoch 113: est. objective value: 0.6128232524748636
epoch 114: generating 100 training examples...
epoch 114: training using 1 minibatches of size 100...
epoch 114: evaluating on 100 examples...
epoch 114: est. objective value: 0.6874108118904837
epoch 115: generating 100 training examples...
epoch 115: training using 1 minibatches of size 100...
epoch 115: evaluating on 100 examples...
epoch 115: est. objective value: 0.7371402170991702
epoch 116: generating 100 training examples...
epoch 116: training using 1 minibatches of size 100...
epoch 116: evaluating on 100 examples...
epoch 116: est. objective value: 0.7296641648620801
epoch 117: generating 100 training examples...
epoch 117: training using 1 minibatches of size 100...
epoch 117: evaluating on 100 examples...
epoch 117: est. objective value: 0.6677548562698981
epoch 118: generating 100 training examples...
epoch 118: training using 1 minibatches of size 100...
epoch 118: evaluating on 100 examples...
epoch 118: est. objective value: 0.7846019690656764
epoch 119: generating 100 training examples...
epoch 119: training using 1 minibatches of size 100...
epoch 119: evaluating on 100 examples...
epoch 119: est. objective value: 0.7840500994765133
epoch 120: generating 100 training examples...
epoch 120: training using 1 minibatches of size 100...
epoch 120: evaluating on 100 examples...
epoch 120: est. objective value: 0.7122865923897946
epoch 121: generating 100 training examples...
epoch 121: training using 1 minibatches of size 100...
epoch 121: evaluating on 100 examples...
epoch 121: est. objective value: 0.7535857226925942
epoch 122: generating 100 training examples...
epoch 122: training using 1 minibatches of size 100...
epoch 122: evaluating on 100 examples...
epoch 122: est. objective value: 0.8022634050946766
epoch 123: generating 100 training examples...
epoch 123: training using 1 minibatches of size 100...
epoch 123: evaluating on 100 examples...
epoch 123: est. objective value: 0.6977703272599726
epoch 124: generating 100 training examples...
epoch 124: training using 1 minibatches of size 100...
epoch 124: evaluating on 100 examples...
epoch 124: est. objective value: 0.7539188968581285
epoch 125: generating 100 training examples...
epoch 125: training using 1 minibatches of size 100...
epoch 125: evaluating on 100 examples...
epoch 125: est. objective value: 0.5779159619153779
epoch 126: generating 100 training examples...
epoch 126: training using 1 minibatches of size 100...
epoch 126: evaluating on 100 examples...
epoch 126: est. objective value: 0.559699949929576
epoch 127: generating 100 training examples...
epoch 127: training using 1 minibatches of size 100...
epoch 127: evaluating on 100 examples...
epoch 127: est. objective value: 0.5976851636510238
epoch 128: generating 100 training examples...
epoch 128: training using 1 minibatches of size 100...
epoch 128: evaluating on 100 examples...
epoch 128: est. objective value: 0.725930836925354
epoch 129: generating 100 training examples...
epoch 129: training using 1 minibatches of size 100...
epoch 129: evaluating on 100 examples...
epoch 129: est. objective value: 0.6505804160260312
epoch 130: generating 100 training examples...
epoch 130: training using 1 minibatches of size 100...
epoch 130: evaluating on 100 examples...
epoch 130: est. objective value: 0.5453492742157776
epoch 131: generating 100 training examples...
epoch 131: training using 1 minibatches of size 100...
epoch 131: evaluating on 100 examples...
epoch 131: est. objective value: 0.7631742230236418
epoch 132: generating 100 training examples...
epoch 132: training using 1 minibatches of size 100...
epoch 132: evaluating on 100 examples...
epoch 132: est. objective value: 0.6166692246231029
epoch 133: generating 100 training examples...
epoch 133: training using 1 minibatches of size 100...
epoch 133: evaluating on 100 examples...
epoch 133: est. objective value: 0.7342154922027336
epoch 134: generating 100 training examples...
epoch 134: training using 1 minibatches of size 100...
epoch 134: evaluating on 100 examples...
epoch 134: est. objective value: 0.8893746535508906
epoch 135: generating 100 training examples...
epoch 135: training using 1 minibatches of size 100...
epoch 135: evaluating on 100 examples...
epoch 135: est. objective value: 0.5758272537496326
epoch 136: generating 100 training examples...
epoch 136: training using 1 minibatches of size 100...
epoch 136: evaluating on 100 examples...
epoch 136: est. objective value: 0.7566301004704709
epoch 137: generating 100 training examples...
epoch 137: training using 1 minibatches of size 100...
epoch 137: evaluating on 100 examples...
epoch 137: est. objective value: 0.8613125739375296
epoch 138: generating 100 training examples...
epoch 138: training using 1 minibatches of size 100...
epoch 138: evaluating on 100 examples...
epoch 138: est. objective value: 0.7451297664172044
epoch 139: generating 100 training examples...
epoch 139: training using 1 minibatches of size 100...
epoch 139: evaluating on 100 examples...
epoch 139: est. objective value: 0.809260817169572
epoch 140: generating 100 training examples...
epoch 140: training using 1 minibatches of size 100...
epoch 140: evaluating on 100 examples...
epoch 140: est. objective value: 0.6699932230940435
epoch 141: generating 100 training examples...
epoch 141: training using 1 minibatches of size 100...
epoch 141: evaluating on 100 examples...
epoch 141: est. objective value: 0.90043411239157
epoch 142: generating 100 training examples...
epoch 142: training using 1 minibatches of size 100...
epoch 142: evaluating on 100 examples...
epoch 142: est. objective value: 0.8093850904292527
epoch 143: generating 100 training examples...
epoch 143: training using 1 minibatches of size 100...
epoch 143: evaluating on 100 examples...
epoch 143: est. objective value: 0.6840653499737778
epoch 144: generating 100 training examples...
epoch 144: training using 1 minibatches of size 100...
epoch 144: evaluating on 100 examples...
epoch 144: est. objective value: 0.6670813981720404
epoch 145: generating 100 training examples...
epoch 145: training using 1 minibatches of size 100...
epoch 145: evaluating on 100 examples...
epoch 145: est. objective value: 0.8184314865407915
epoch 146: generating 100 training examples...
epoch 146: training using 1 minibatches of size 100...
epoch 146: evaluating on 100 examples...
epoch 146: est. objective value: 0.6848442001415667
epoch 147: generating 100 training examples...
epoch 147: training using 1 minibatches of size 100...
epoch 147: evaluating on 100 examples...
epoch 147: est. objective value: 0.8026686848314284
epoch 148: generating 100 training examples...
epoch 148: training using 1 minibatches of size 100...
epoch 148: evaluating on 100 examples...
epoch 148: est. objective value: 0.7955507495862422
epoch 149: generating 100 training examples...
epoch 149: training using 1 minibatches of size 100...
epoch 149: evaluating on 100 examples...
epoch 149: est. objective value: 0.6718157074871414
epoch 150: generating 100 training examples...
epoch 150: training using 1 minibatches of size 100...
epoch 150: evaluating on 100 examples...
epoch 150: est. objective value: 0.6563301757399357
epoch 151: generating 100 training examples...
epoch 151: training using 1 minibatches of size 100...
epoch 151: evaluating on 100 examples...
epoch 151: est. objective value: 0.5053657713452809
epoch 152: generating 100 training examples...
epoch 152: training using 1 minibatches of size 100...
epoch 152: evaluating on 100 examples...
epoch 152: est. objective value: 0.891863999250468
epoch 153: generating 100 training examples...
epoch 153: training using 1 minibatches of size 100...
epoch 153: evaluating on 100 examples...
epoch 153: est. objective value: 0.8726641505849149
epoch 154: generating 100 training examples...
epoch 154: training using 1 minibatches of size 100...
epoch 154: evaluating on 100 examples...
epoch 154: est. objective value: 0.6444949681528048
epoch 155: generating 100 training examples...
epoch 155: training using 1 minibatches of size 100...
epoch 155: evaluating on 100 examples...
epoch 155: est. objective value: 0.7795233494130716
epoch 156: generating 100 training examples...
epoch 156: training using 1 minibatches of size 100...
epoch 156: evaluating on 100 examples...
epoch 156: est. objective value: 0.6518417006376578
epoch 157: generating 100 training examples...
epoch 157: training using 1 minibatches of size 100...
epoch 157: evaluating on 100 examples...
epoch 157: est. objective value: 0.7346300921880836
epoch 158: generating 100 training examples...
epoch 158: training using 1 minibatches of size 100...
epoch 158: evaluating on 100 examples...
epoch 158: est. objective value: 0.8089605701190125
epoch 159: generating 100 training examples...
epoch 159: training using 1 minibatches of size 100...
epoch 159: evaluating on 100 examples...
epoch 159: est. objective value: 0.8913781319618822
epoch 160: generating 100 training examples...
epoch 160: training using 1 minibatches of size 100...
epoch 160: evaluating on 100 examples...
epoch 160: est. objective value: 0.6903417486215511
epoch 161: generating 100 training examples...
epoch 161: training using 1 minibatches of size 100...
epoch 161: evaluating on 100 examples...
epoch 161: est. objective value: 0.7801890566470856
epoch 162: generating 100 training examples...
epoch 162: training using 1 minibatches of size 100...
epoch 162: evaluating on 100 examples...
epoch 162: est. objective value: 0.6043681876885124
epoch 163: generating 100 training examples...
epoch 163: training using 1 minibatches of size 100...
epoch 163: evaluating on 100 examples...
epoch 163: est. objective value: 0.6582537792341502
epoch 164: generating 100 training examples...
epoch 164: training using 1 minibatches of size 100...
epoch 164: evaluating on 100 examples...
epoch 164: est. objective value: 0.8161479051569812
epoch 165: generating 100 training examples...
epoch 165: training using 1 minibatches of size 100...
epoch 165: evaluating on 100 examples...
epoch 165: est. objective value: 0.6586429925392001
epoch 166: generating 100 training examples...
epoch 166: training using 1 minibatches of size 100...
epoch 166: evaluating on 100 examples...
epoch 166: est. objective value: 0.953311260882552
epoch 167: generating 100 training examples...
epoch 167: training using 1 minibatches of size 100...
epoch 167: evaluating on 100 examples...
epoch 167: est. objective value: 0.8026551786921998
epoch 168: generating 100 training examples...
epoch 168: training using 1 minibatches of size 100...
epoch 168: evaluating on 100 examples...
epoch 168: est. objective value: 0.7585336239629273
epoch 169: generating 100 training examples...
epoch 169: training using 1 minibatches of size 100...
epoch 169: evaluating on 100 examples...
epoch 169: est. objective value: 0.8600245069821103
epoch 170: generating 100 training examples...
epoch 170: training using 1 minibatches of size 100...
epoch 170: evaluating on 100 examples...
epoch 170: est. objective value: 0.6772536045042082
epoch 171: generating 100 training examples...
epoch 171: training using 1 minibatches of size 100...
epoch 171: evaluating on 100 examples...
epoch 171: est. objective value: 0.5396604022805078
epoch 172: generating 100 training examples...
epoch 172: training using 1 minibatches of size 100...
epoch 172: evaluating on 100 examples...
epoch 172: est. objective value: 0.4643673422716513
epoch 173: generating 100 training examples...
epoch 173: training using 1 minibatches of size 100...
epoch 173: evaluating on 100 examples...
epoch 173: est. objective value: 0.7478228334523362
epoch 174: generating 100 training examples...
epoch 174: training using 1 minibatches of size 100...
epoch 174: evaluating on 100 examples...
epoch 174: est. objective value: 1.0311096562795505
epoch 175: generating 100 training examples...
epoch 175: training using 1 minibatches of size 100...
epoch 175: evaluating on 100 examples...
epoch 175: est. objective value: 0.7433167979940886
epoch 176: generating 100 training examples...
epoch 176: training using 1 minibatches of size 100...
epoch 176: evaluating on 100 examples...
epoch 176: est. objective value: 0.8962771018928106
epoch 177: generating 100 training examples...
epoch 177: training using 1 minibatches of size 100...
epoch 177: evaluating on 100 examples...
epoch 177: est. objective value: 0.9429582175156601
epoch 178: generating 100 training examples...
epoch 178: training using 1 minibatches of size 100...
epoch 178: evaluating on 100 examples...
epoch 178: est. objective value: 0.6198313385585404
epoch 179: generating 100 training examples...
epoch 179: training using 1 minibatches of size 100...
epoch 179: evaluating on 100 examples...
epoch 179: est. objective value: 0.6306706749784752
epoch 180: generating 100 training examples...
epoch 180: training using 1 minibatches of size 100...
epoch 180: evaluating on 100 examples...
epoch 180: est. objective value: 0.7147791614762453
epoch 181: generating 100 training examples...
epoch 181: training using 1 minibatches of size 100...
epoch 181: evaluating on 100 examples...
epoch 181: est. objective value: 0.7420948555829008
epoch 182: generating 100 training examples...
epoch 182: training using 1 minibatches of size 100...
epoch 182: evaluating on 100 examples...
epoch 182: est. objective value: 0.7633516088169359
epoch 183: generating 100 training examples...
epoch 183: training using 1 minibatches of size 100...
epoch 183: evaluating on 100 examples...
epoch 183: est. objective value: 0.7853482268128411
epoch 184: generating 100 training examples...
epoch 184: training using 1 minibatches of size 100...
epoch 184: evaluating on 100 examples...
epoch 184: est. objective value: 0.7619267808135721
epoch 185: generating 100 training examples...
epoch 185: training using 1 minibatches of size 100...
epoch 185: evaluating on 100 examples...
epoch 185: est. objective value: 0.6541847488321363
epoch 186: generating 100 training examples...
epoch 186: training using 1 minibatches of size 100...
epoch 186: evaluating on 100 examples...
epoch 186: est. objective value: 0.9533814380771344
epoch 187: generating 100 training examples...
epoch 187: training using 1 minibatches of size 100...
epoch 187: evaluating on 100 examples...
epoch 187: est. objective value: 0.7658595303213531
epoch 188: generating 100 training examples...
epoch 188: training using 1 minibatches of size 100...
epoch 188: evaluating on 100 examples...
epoch 188: est. objective value: 0.6951403760085352
epoch 189: generating 100 training examples...
epoch 189: training using 1 minibatches of size 100...
epoch 189: evaluating on 100 examples...
epoch 189: est. objective value: 0.9849688160909001
epoch 190: generating 100 training examples...
epoch 190: training using 1 minibatches of size 100...
epoch 190: evaluating on 100 examples...
epoch 190: est. objective value: 0.8233251916434753
epoch 191: generating 100 training examples...
epoch 191: training using 1 minibatches of size 100...
epoch 191: evaluating on 100 examples...
epoch 191: est. objective value: 0.7602948064844022
epoch 192: generating 100 training examples...
epoch 192: training using 1 minibatches of size 100...
epoch 192: evaluating on 100 examples...
epoch 192: est. objective value: 0.5704164603621288
epoch 193: generating 100 training examples...
epoch 193: training using 1 minibatches of size 100...
epoch 193: evaluating on 100 examples...
epoch 193: est. objective value: 0.8391940111179456
epoch 194: generating 100 training examples...
epoch 194: training using 1 minibatches of size 100...
epoch 194: evaluating on 100 examples...
epoch 194: est. objective value: 0.8949163217376293
epoch 195: generating 100 training examples...
epoch 195: training using 1 minibatches of size 100...
epoch 195: evaluating on 100 examples...
epoch 195: est. objective value: 0.8782247667465358
epoch 196: generating 100 training examples...
epoch 196: training using 1 minibatches of size 100...
epoch 196: evaluating on 100 examples...
epoch 196: est. objective value: 0.7307472074036829
epoch 197: generating 100 training examples...
epoch 197: training using 1 minibatches of size 100...
epoch 197: evaluating on 100 examples...
epoch 197: est. objective value: 0.8859784219808615
epoch 198: generating 100 training examples...
epoch 198: training using 1 minibatches of size 100...
epoch 198: evaluating on 100 examples...
epoch 198: est. objective value: 0.8898881181495891
epoch 199: generating 100 training examples...
epoch 199: training using 1 minibatches of size 100...
epoch 199: evaluating on 100 examples...
epoch 199: est. objective value: 0.714231271321208
epoch 200: generating 100 training examples...
epoch 200: training using 1 minibatches of size 100...
epoch 200: evaluating on 100 examples...
epoch 200: est. objective value: 0.48226875566596256
 31.070067 seconds (46.10 M allocations: 2.840 GiB, 0.96% gc time, 4.32% compilation time)
</code></pre></div></div>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">using</span> <span class="n">Plots</span>
<span class="n">plot</span><span class="x">(</span><span class="n">scores</span><span class="x">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s">"Iterations of stochastic gradient descent"</span><span class="x">,</span> <span class="n">labelfontsize</span><span class="o">=</span><span class="mi">8</span><span class="x">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s">"Estimate of expected conditional log probability density"</span><span class="x">,</span> <span class="n">label</span><span class="o">=</span><span class="n">nothing</span><span class="x">)</span>
</code></pre></div></div>

<p><img src="output_123_0.svg" alt="svg" /></p>

<p>We can read out the new value for <code class="highlighter-rouge">score_high</code>:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">println</span><span class="x">(</span><span class="n">exp</span><span class="x">(</span><span class="n">Gen</span><span class="o">.</span><span class="n">get_param</span><span class="x">(</span><span class="n">custom_dest_proposal_trainable</span><span class="x">,</span> <span class="x">:</span><span class="n">log_score_high</span><span class="x">)))</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>9.434368409103923
</code></pre></div></div>

<p>We see that the optimal value of the parameter is indeed larger than our
initial guess. This validates that the heuristic is indeed a useful one. We
visualize the proposal distribution below:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">visualize_custom_destination_proposal</span><span class="x">(</span><span class="n">measurements</span><span class="x">,</span> <span class="n">start</span><span class="x">,</span> <span class="n">custom_dest_proposal_trainable</span><span class="x">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1000</span><span class="x">)</span>
</code></pre></div></div>

<p><img src="output_127_0.png" alt="png" /></p>

<p>We can visualize the results of inference, using this newly trained proposal:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">visualize_data_driven_inference</span><span class="x">(</span><span class="n">measurements</span><span class="x">,</span> <span class="n">scene</span><span class="x">,</span> <span class="n">start</span><span class="x">,</span> <span class="n">custom_dest_proposal_trainable</span><span class="x">,</span>
    <span class="n">amt_computation</span><span class="o">=</span><span class="mi">5</span><span class="x">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">1000</span><span class="x">)</span>
</code></pre></div></div>

<p><img src="output_129_0.png" alt="png" /></p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">visualize_data_driven_inference</span><span class="x">(</span><span class="n">measurements</span><span class="x">,</span> <span class="n">scene</span><span class="x">,</span> <span class="n">start</span><span class="x">,</span> <span class="n">custom_dest_proposal_trainable</span><span class="x">,</span>
    <span class="n">amt_computation</span><span class="o">=</span><span class="mi">10</span><span class="x">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">1000</span><span class="x">)</span>
</code></pre></div></div>

<p><img src="output_130_0.png" alt="png" /></p>

<hr />

<h3 id="exercise-6">Exercise</h3>

<p>Can you devise a data-driven proposal for the speed of the agent? If so, would you
expect it to work equally well on all data sets?</p>

<hr />

<h2 id="5-writing-and-training-a-deep-learning-based-data-driven-proposal-">5. Writing and training a deep learning based data-driven proposal <a name="deep"></a></h2>

<p>The heuristic data-driven proposal above gave some improvement in efficiency,
but it was very simple. One way of constructing complex data-driven proposals
is to parametrize the proposal with a deep neural network or use another
class of high-capacity machine learning model (e.g. random forest). Here, we
will will write a data-driven proposal for the destination of the agent that
uses deep neural networks. In this section, we do everything manually, without
the aid of neural network libraries. We also provide an <a href="#">extension to the tutorial</a> that
shows how to use PyTorch to make this process a lot easier.</p>

<p>First, we define a sigmoid function for the nonlinearity in our networks.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nonlinearity</span><span class="x">(</span><span class="n">x</span><span class="x">)</span> <span class="o">=</span> <span class="mf">1.7159</span> <span class="o">*</span> <span class="n">tanh</span><span class="o">.</span><span class="x">(</span><span class="n">x</span> <span class="o">*</span> <span class="mf">0.66666</span><span class="x">);</span>
</code></pre></div></div>

<p>We will use a deep neural network with two hidden layers that takes as input
x- and y- coordinates of the first and last measurement (4 values) and
produces as output a vector of un-normalized probabilities, one for each bin
of the x-dimension. We will later sample <code class="highlighter-rouge">:dest_x</code> from this distribution.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span><span class="nf"> dest_x_neural_net</span><span class="x">(</span><span class="n">nn_params</span><span class="x">,</span> <span class="n">x_first</span><span class="o">::</span><span class="n">Real</span><span class="x">,</span> <span class="n">y_first</span><span class="o">::</span><span class="n">Real</span><span class="x">,</span> <span class="n">x_last</span><span class="o">::</span><span class="n">Real</span><span class="x">,</span> <span class="n">y_last</span><span class="o">::</span><span class="n">Real</span><span class="x">)</span>
    <span class="x">(</span><span class="n">W1</span><span class="x">,</span> <span class="n">b1</span><span class="x">,</span> <span class="n">W2</span><span class="x">,</span> <span class="n">b2</span><span class="x">,</span> <span class="n">W3</span><span class="x">,</span> <span class="n">b3</span><span class="x">)</span> <span class="o">=</span> <span class="n">nn_params</span>
    <span class="n">input_layer</span> <span class="o">=</span> <span class="x">[</span><span class="n">x_first</span><span class="x">,</span> <span class="n">y_first</span><span class="x">,</span> <span class="n">x_last</span><span class="x">,</span> <span class="n">y_last</span><span class="x">]</span>
    <span class="n">hidden_layer_1</span> <span class="o">=</span> <span class="n">nonlinearity</span><span class="x">(</span><span class="n">W1</span> <span class="o">*</span> <span class="n">input_layer</span> <span class="o">.+</span> <span class="n">b1</span><span class="x">)</span>
    <span class="n">hidden_layer_2</span> <span class="o">=</span> <span class="n">nonlinearity</span><span class="x">(</span><span class="n">W2</span> <span class="o">*</span> <span class="n">hidden_layer_1</span> <span class="o">.+</span> <span class="n">b2</span><span class="x">)</span>
    <span class="n">output_layer</span> <span class="o">=</span> <span class="n">exp</span><span class="o">.</span><span class="x">(</span><span class="n">W3</span> <span class="o">*</span> <span class="n">hidden_layer_2</span> <span class="o">.+</span> <span class="n">b3</span><span class="x">)</span>
    <span class="k">return</span> <span class="n">output_layer</span>
<span class="k">end</span><span class="x">;</span>
</code></pre></div></div>

<p>After sampling the value of <code class="highlighter-rouge">:dest_x</code>, we will use a second deep neural
network with the same structure to sample <code class="highlighter-rouge">:dest_y</code>.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">function</span><span class="nf"> dest_y_neural_net</span><span class="x">(</span><span class="n">nn_params</span><span class="x">,</span> <span class="n">x_first</span><span class="o">::</span><span class="n">Real</span><span class="x">,</span> <span class="n">y_first</span><span class="o">::</span><span class="n">Real</span><span class="x">,</span> <span class="n">x_last</span><span class="o">::</span><span class="n">Real</span><span class="x">,</span> <span class="n">y_last</span><span class="o">::</span><span class="n">Real</span><span class="x">)</span><span class="c">#, dest_x::Real)</span>
    <span class="x">(</span><span class="n">W1</span><span class="x">,</span> <span class="n">b1</span><span class="x">,</span> <span class="n">W2</span><span class="x">,</span> <span class="n">b2</span><span class="x">,</span> <span class="n">W3</span><span class="x">,</span> <span class="n">b3</span><span class="x">)</span> <span class="o">=</span> <span class="n">nn_params</span>
    <span class="n">input_layer</span> <span class="o">=</span> <span class="x">[</span><span class="n">x_first</span><span class="x">,</span> <span class="n">y_first</span><span class="x">,</span> <span class="n">x_last</span><span class="x">,</span> <span class="n">y_last</span><span class="x">]</span>
    <span class="n">hidden_layer_1</span> <span class="o">=</span> <span class="n">nonlinearity</span><span class="x">(</span><span class="n">W1</span> <span class="o">*</span> <span class="n">input_layer</span> <span class="o">.+</span> <span class="n">b1</span><span class="x">)</span>
    <span class="n">hidden_layer_2</span> <span class="o">=</span> <span class="n">nonlinearity</span><span class="x">(</span><span class="n">W2</span> <span class="o">*</span> <span class="n">hidden_layer_1</span> <span class="o">.+</span> <span class="n">b2</span><span class="x">)</span>
    <span class="n">output_layer</span> <span class="o">=</span> <span class="n">exp</span><span class="o">.</span><span class="x">(</span><span class="n">W3</span> <span class="o">*</span> <span class="n">hidden_layer_2</span> <span class="o">.+</span> <span class="n">b3</span><span class="x">)</span>
    <span class="k">return</span> <span class="n">output_layer</span>
<span class="k">end</span><span class="x">;</span>
</code></pre></div></div>

<p>Now that we have defined our neural networks, we define our new proposal.
This generative function has a number of parameters.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scale_coord</span><span class="x">(</span><span class="n">coord</span><span class="x">,</span> <span class="n">min</span><span class="x">,</span> <span class="n">max</span><span class="x">)</span> <span class="o">=</span> <span class="x">(</span><span class="n">coord</span> <span class="o">/</span> <span class="x">(</span><span class="n">max</span> <span class="o">-</span> <span class="n">min</span><span class="x">))</span> <span class="o">-</span> <span class="mf">0.5</span>

<span class="nd">@gen</span> <span class="k">function</span><span class="nf"> custom_dest_proposal_neural</span><span class="x">(</span><span class="n">measurements</span><span class="o">::</span><span class="n">Vector</span><span class="x">{</span><span class="n">Point</span><span class="x">},</span> <span class="n">scene</span><span class="o">::</span><span class="n">Scene</span><span class="x">)</span>
    <span class="nd">@param</span> <span class="n">x_W1</span><span class="o">::</span><span class="n">Matrix</span><span class="x">{</span><span class="kt">Float64</span><span class="x">}</span>
    <span class="nd">@param</span> <span class="n">x_b1</span><span class="o">::</span><span class="n">Vector</span><span class="x">{</span><span class="kt">Float64</span><span class="x">}</span>
    <span class="nd">@param</span> <span class="n">x_W2</span><span class="o">::</span><span class="n">Matrix</span><span class="x">{</span><span class="kt">Float64</span><span class="x">}</span>
    <span class="nd">@param</span> <span class="n">x_b2</span><span class="o">::</span><span class="n">Vector</span><span class="x">{</span><span class="kt">Float64</span><span class="x">}</span>
    <span class="nd">@param</span> <span class="n">x_W3</span><span class="o">::</span><span class="n">Matrix</span><span class="x">{</span><span class="kt">Float64</span><span class="x">}</span>
    <span class="nd">@param</span> <span class="n">x_b3</span><span class="o">::</span><span class="n">Vector</span><span class="x">{</span><span class="kt">Float64</span><span class="x">}</span>
    
    <span class="nd">@param</span> <span class="n">y_W1</span><span class="o">::</span><span class="n">Matrix</span><span class="x">{</span><span class="kt">Float64</span><span class="x">}</span>
    <span class="nd">@param</span> <span class="n">y_b1</span><span class="o">::</span><span class="n">Vector</span><span class="x">{</span><span class="kt">Float64</span><span class="x">}</span>
    <span class="nd">@param</span> <span class="n">y_W2</span><span class="o">::</span><span class="n">Matrix</span><span class="x">{</span><span class="kt">Float64</span><span class="x">}</span>
    <span class="nd">@param</span> <span class="n">y_b2</span><span class="o">::</span><span class="n">Vector</span><span class="x">{</span><span class="kt">Float64</span><span class="x">}</span>
    <span class="nd">@param</span> <span class="n">y_W3</span><span class="o">::</span><span class="n">Matrix</span><span class="x">{</span><span class="kt">Float64</span><span class="x">}</span>
    <span class="nd">@param</span> <span class="n">y_b3</span><span class="o">::</span><span class="n">Vector</span><span class="x">{</span><span class="kt">Float64</span><span class="x">}</span>
    
    <span class="n">num_x_bins</span> <span class="o">=</span> <span class="n">length</span><span class="x">(</span><span class="n">x_b3</span><span class="x">)</span>
    <span class="n">num_y_bins</span> <span class="o">=</span> <span class="n">length</span><span class="x">(</span><span class="n">y_b3</span><span class="x">)</span>
    
    <span class="c"># scale inputs to be in the range [-0.5, 0.5]</span>
    <span class="n">x_first</span> <span class="o">=</span> <span class="n">scale_coord</span><span class="x">(</span><span class="n">measurements</span><span class="x">[</span><span class="mi">1</span><span class="x">]</span><span class="o">.</span><span class="n">x</span><span class="x">,</span> <span class="n">scene</span><span class="o">.</span><span class="n">xmin</span><span class="x">,</span> <span class="n">scene</span><span class="o">.</span><span class="n">xmax</span><span class="x">)</span>
    <span class="n">x_last</span> <span class="o">=</span> <span class="n">scale_coord</span><span class="x">(</span><span class="n">measurements</span><span class="x">[</span><span class="k">end</span><span class="x">]</span><span class="o">.</span><span class="n">x</span><span class="x">,</span> <span class="n">scene</span><span class="o">.</span><span class="n">xmin</span><span class="x">,</span> <span class="n">scene</span><span class="o">.</span><span class="n">xmax</span><span class="x">)</span>
    <span class="n">y_first</span> <span class="o">=</span> <span class="n">scale_coord</span><span class="x">(</span><span class="n">measurements</span><span class="x">[</span><span class="mi">1</span><span class="x">]</span><span class="o">.</span><span class="n">y</span><span class="x">,</span> <span class="n">scene</span><span class="o">.</span><span class="n">ymin</span><span class="x">,</span> <span class="n">scene</span><span class="o">.</span><span class="n">ymax</span><span class="x">)</span>
    <span class="n">y_last</span> <span class="o">=</span> <span class="n">scale_coord</span><span class="x">(</span><span class="n">measurements</span><span class="x">[</span><span class="k">end</span><span class="x">]</span><span class="o">.</span><span class="n">y</span><span class="x">,</span> <span class="n">scene</span><span class="o">.</span><span class="n">ymin</span><span class="x">,</span> <span class="n">scene</span><span class="o">.</span><span class="n">ymax</span><span class="x">)</span>
    
    <span class="c"># sample dest_x</span>
    <span class="n">x_bounds</span> <span class="o">=</span> <span class="n">collect</span><span class="x">(</span><span class="n">range</span><span class="x">(</span><span class="n">scene</span><span class="o">.</span><span class="n">xmin</span><span class="x">,</span> <span class="n">stop</span><span class="o">=</span><span class="n">scene</span><span class="o">.</span><span class="n">xmax</span><span class="x">,</span> <span class="n">length</span><span class="o">=</span><span class="n">num_x_bins</span><span class="o">+</span><span class="mi">1</span><span class="x">))</span>
    <span class="n">x_probs</span> <span class="o">=</span> <span class="n">dest_x_neural_net</span><span class="x">((</span><span class="n">x_W1</span><span class="x">,</span> <span class="n">x_b1</span><span class="x">,</span> <span class="n">x_W2</span><span class="x">,</span> <span class="n">x_b2</span><span class="x">,</span> <span class="n">x_W3</span><span class="x">,</span> <span class="n">x_b3</span><span class="x">),</span> <span class="n">x_first</span><span class="x">,</span> <span class="n">y_first</span><span class="x">,</span> <span class="n">x_last</span><span class="x">,</span> <span class="n">y_last</span><span class="x">)</span>
    <span class="n">dest_x</span> <span class="o">~</span> <span class="n">piecewise_uniform</span><span class="x">(</span><span class="n">x_bounds</span><span class="x">,</span> <span class="n">x_probs</span> <span class="o">/</span> <span class="n">sum</span><span class="x">(</span><span class="n">x_probs</span><span class="x">))</span>
    
    <span class="c"># sample dest_y</span>
    <span class="n">y_bounds</span> <span class="o">=</span> <span class="n">collect</span><span class="x">(</span><span class="n">range</span><span class="x">(</span><span class="n">scene</span><span class="o">.</span><span class="n">xmin</span><span class="x">,</span> <span class="n">stop</span><span class="o">=</span><span class="n">scene</span><span class="o">.</span><span class="n">xmax</span><span class="x">,</span> <span class="n">length</span><span class="o">=</span><span class="n">num_y_bins</span><span class="o">+</span><span class="mi">1</span><span class="x">))</span>
    <span class="n">y_probs</span> <span class="o">=</span> <span class="n">dest_y_neural_net</span><span class="x">((</span><span class="n">y_W1</span><span class="x">,</span> <span class="n">y_b1</span><span class="x">,</span> <span class="n">y_W2</span><span class="x">,</span> <span class="n">y_b2</span><span class="x">,</span> <span class="n">y_W3</span><span class="x">,</span> <span class="n">y_b3</span><span class="x">),</span> <span class="n">x_first</span><span class="x">,</span> <span class="n">y_first</span><span class="x">,</span> <span class="n">x_last</span><span class="x">,</span> <span class="n">y_last</span><span class="x">)</span>
    <span class="n">dest_y</span> <span class="o">~</span> <span class="n">Gen</span><span class="o">.</span><span class="n">piecewise_uniform</span><span class="x">(</span><span class="n">y_bounds</span><span class="x">,</span> <span class="n">y_probs</span> <span class="o">/</span> <span class="n">sum</span><span class="x">(</span><span class="n">y_probs</span><span class="x">))</span>
    
    <span class="k">return</span> <span class="n">nothing</span>
<span class="k">end</span><span class="x">;</span>
</code></pre></div></div>

<p>We will use 50 hidden units in each of the layers of the two networks:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_hidden_1</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">num_hidden_2</span> <span class="o">=</span> <span class="mi">50</span><span class="x">;</span>
</code></pre></div></div>

<p>Next, we initialize the parameters:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">import</span> <span class="n">Random</span>
<span class="n">Random</span><span class="o">.</span><span class="n">seed!</span><span class="x">(</span><span class="mi">3</span><span class="x">)</span>

<span class="n">init_weight</span><span class="x">(</span><span class="n">shape</span><span class="o">...</span><span class="x">)</span> <span class="o">=</span> <span class="x">(</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">sqrt</span><span class="x">(</span><span class="n">shape</span><span class="x">[</span><span class="mi">2</span><span class="x">]))</span> <span class="o">*</span> <span class="n">randn</span><span class="x">(</span><span class="n">shape</span><span class="o">...</span><span class="x">)</span>

<span class="n">init_x_W1</span> <span class="o">=</span> <span class="n">init_weight</span><span class="x">(</span><span class="n">num_hidden_1</span><span class="x">,</span> <span class="mi">4</span><span class="x">)</span>
<span class="n">init_x_W2</span> <span class="o">=</span> <span class="n">init_weight</span><span class="x">(</span><span class="n">num_hidden_2</span><span class="x">,</span> <span class="n">num_hidden_1</span><span class="x">)</span>
<span class="n">init_x_W3</span> <span class="o">=</span> <span class="n">init_weight</span><span class="x">(</span><span class="n">num_x_bins</span><span class="x">,</span> <span class="n">num_hidden_2</span><span class="x">)</span>

<span class="c"># set parameters for dest_x_neural_net predictor network</span>
<span class="n">init_param!</span><span class="x">(</span><span class="n">custom_dest_proposal_neural</span><span class="x">,</span> <span class="x">:</span><span class="n">x_W1</span><span class="x">,</span> <span class="n">init_x_W1</span><span class="x">)</span>
<span class="n">init_param!</span><span class="x">(</span><span class="n">custom_dest_proposal_neural</span><span class="x">,</span> <span class="x">:</span><span class="n">x_b1</span><span class="x">,</span> <span class="n">zeros</span><span class="x">(</span><span class="n">num_hidden_1</span><span class="x">))</span>
<span class="n">init_param!</span><span class="x">(</span><span class="n">custom_dest_proposal_neural</span><span class="x">,</span> <span class="x">:</span><span class="n">x_W2</span><span class="x">,</span> <span class="n">init_x_W2</span><span class="x">)</span>
<span class="n">init_param!</span><span class="x">(</span><span class="n">custom_dest_proposal_neural</span><span class="x">,</span> <span class="x">:</span><span class="n">x_b2</span><span class="x">,</span> <span class="n">zeros</span><span class="x">(</span><span class="n">num_hidden_2</span><span class="x">))</span>
<span class="n">init_param!</span><span class="x">(</span><span class="n">custom_dest_proposal_neural</span><span class="x">,</span> <span class="x">:</span><span class="n">x_W3</span><span class="x">,</span> <span class="n">init_x_W3</span><span class="x">)</span>
<span class="n">init_param!</span><span class="x">(</span><span class="n">custom_dest_proposal_neural</span><span class="x">,</span> <span class="x">:</span><span class="n">x_b3</span><span class="x">,</span> <span class="n">zeros</span><span class="x">(</span><span class="n">num_x_bins</span><span class="x">))</span>

<span class="n">init_y_W1</span> <span class="o">=</span> <span class="n">init_weight</span><span class="x">(</span><span class="n">num_hidden_1</span><span class="x">,</span> <span class="mi">4</span><span class="x">)</span>
<span class="n">init_y_W2</span> <span class="o">=</span> <span class="n">init_weight</span><span class="x">(</span><span class="n">num_hidden_2</span><span class="x">,</span> <span class="n">num_hidden_1</span><span class="x">)</span>
<span class="n">init_y_W3</span> <span class="o">=</span> <span class="n">init_weight</span><span class="x">(</span><span class="n">num_x_bins</span><span class="x">,</span> <span class="n">num_hidden_2</span><span class="x">)</span>

<span class="c"># set parameters for dest_y_neural_net predictor network</span>
<span class="n">init_param!</span><span class="x">(</span><span class="n">custom_dest_proposal_neural</span><span class="x">,</span> <span class="x">:</span><span class="n">y_W1</span><span class="x">,</span> <span class="n">init_y_W1</span><span class="x">)</span>
<span class="n">init_param!</span><span class="x">(</span><span class="n">custom_dest_proposal_neural</span><span class="x">,</span> <span class="x">:</span><span class="n">y_b1</span><span class="x">,</span> <span class="n">zeros</span><span class="x">(</span><span class="n">num_hidden_1</span><span class="x">))</span>
<span class="n">init_param!</span><span class="x">(</span><span class="n">custom_dest_proposal_neural</span><span class="x">,</span> <span class="x">:</span><span class="n">y_W2</span><span class="x">,</span> <span class="n">init_y_W2</span><span class="x">)</span>
<span class="n">init_param!</span><span class="x">(</span><span class="n">custom_dest_proposal_neural</span><span class="x">,</span> <span class="x">:</span><span class="n">y_b2</span><span class="x">,</span> <span class="n">zeros</span><span class="x">(</span><span class="n">num_hidden_2</span><span class="x">))</span>
<span class="n">init_param!</span><span class="x">(</span><span class="n">custom_dest_proposal_neural</span><span class="x">,</span> <span class="x">:</span><span class="n">y_W3</span><span class="x">,</span> <span class="n">init_y_W3</span><span class="x">)</span>
<span class="n">init_param!</span><span class="x">(</span><span class="n">custom_dest_proposal_neural</span><span class="x">,</span> <span class="x">:</span><span class="n">y_b3</span><span class="x">,</span> <span class="n">zeros</span><span class="x">(</span><span class="n">num_y_bins</span><span class="x">));</span>
</code></pre></div></div>

<p>Now, we visualize the proposal distribution prior to training:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">visualize_custom_destination_proposal</span><span class="x">(</span><span class="n">measurements</span><span class="x">,</span> <span class="n">start</span><span class="x">,</span> <span class="n">custom_dest_proposal_neural</span><span class="x">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1000</span><span class="x">)</span>
</code></pre></div></div>

<p><img src="output_149_0.png" alt="png" /></p>

<p>It looks like the initial distribution is roughly uniform, like the default
proposal.</p>

<p>Now we train the network stochastic gradient descent with a fixed step size
of 0.001 that is shared among all of the trainable parameters.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">update</span> <span class="o">=</span> <span class="n">Gen</span><span class="o">.</span><span class="n">ParamUpdate</span><span class="x">(</span><span class="n">Gen</span><span class="o">.</span><span class="n">FixedStepGradientDescent</span><span class="x">(</span><span class="mf">0.001</span><span class="x">),</span> <span class="n">custom_dest_proposal_neural</span><span class="x">);</span>
</code></pre></div></div>

<p>We use 50 epochs of training. In each epoch, we generate 100 training
examples, and we apply 100 gradient updates, where each update is based on
the gradient estimate obtained from a random set of 100 of the trainable
examples. At the end of each epoch, we estimate the objective function value
using 10000 freshly sampled examples. This process takes about 10 minutes to
run on a typical laptop CPU, so we have precomputed the results for you.</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">using</span> <span class="n">JLD2</span>
<span class="nd">@time</span> <span class="n">scores</span> <span class="o">=</span> <span class="n">Gen</span><span class="o">.</span><span class="n">train!</span><span class="x">(</span><span class="n">custom_dest_proposal_neural</span><span class="x">,</span> <span class="n">data_generator</span><span class="x">,</span> <span class="n">update</span><span class="x">,</span>
    <span class="n">num_epoch</span><span class="o">=</span><span class="mi">50</span><span class="x">,</span> <span class="n">epoch_size</span><span class="o">=</span><span class="mi">100</span><span class="x">,</span> <span class="n">num_minibatch</span><span class="o">=</span><span class="mi">100</span><span class="x">,</span> <span class="n">minibatch_size</span><span class="o">=</span><span class="mi">100</span><span class="x">,</span>
    <span class="n">evaluation_size</span><span class="o">=</span><span class="mi">1000</span><span class="x">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">true</span><span class="x">);</span>
    
<span class="n">let</span> <span class="n">data</span> <span class="o">=</span> <span class="n">Dict</span><span class="x">()</span>
    <span class="k">for</span> <span class="n">name</span> <span class="k">in</span> <span class="x">[:</span><span class="n">x_W1</span><span class="x">,</span> <span class="x">:</span><span class="n">x_b1</span><span class="x">,</span> <span class="x">:</span><span class="n">x_W2</span><span class="x">,</span> <span class="x">:</span><span class="n">x_b2</span><span class="x">,</span> <span class="x">:</span><span class="n">x_W3</span><span class="x">,</span> <span class="x">:</span><span class="n">x_b3</span><span class="x">,</span> <span class="x">:</span><span class="n">y_W1</span><span class="x">,</span> <span class="x">:</span><span class="n">y_b1</span><span class="x">,</span> <span class="x">:</span><span class="n">y_W2</span><span class="x">,</span> <span class="x">:</span><span class="n">y_b2</span><span class="x">,</span> <span class="x">:</span><span class="n">y_W3</span><span class="x">,</span> <span class="x">:</span><span class="n">y_b3</span><span class="x">]</span>
        <span class="n">data</span><span class="x">[(:</span><span class="n">param</span><span class="x">,</span> <span class="n">name</span><span class="x">)]</span> <span class="o">=</span> <span class="n">Gen</span><span class="o">.</span><span class="n">get_param</span><span class="x">(</span><span class="n">custom_dest_proposal_neural</span><span class="x">,</span> <span class="n">name</span><span class="x">)</span>
    <span class="k">end</span>
    <span class="n">data</span><span class="x">[:</span><span class="n">scores</span><span class="x">]</span> <span class="o">=</span> <span class="n">scores</span>
    <span class="n">save</span><span class="x">(</span><span class="s">"params/custom_dest_proposal_neural_trained.jld2"</span><span class="x">,</span> <span class="s">"data"</span><span class="x">,</span> <span class="n">data</span><span class="x">)</span>
<span class="k">end</span>
</code></pre></div></div>

<p>We load the results here:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">using</span> <span class="n">JLD2</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">let</span> <span class="n">data</span> <span class="o">=</span> <span class="n">JLD2</span><span class="o">.</span><span class="nb">load</span><span class="x">(</span><span class="s">"params/custom_dest_proposal_neural_trained.jld2"</span><span class="x">,</span> <span class="s">"data"</span><span class="x">)</span>
    <span class="k">for</span> <span class="n">name</span> <span class="k">in</span> <span class="x">[:</span><span class="n">x_W1</span><span class="x">,</span> <span class="x">:</span><span class="n">x_b1</span><span class="x">,</span> <span class="x">:</span><span class="n">x_W2</span><span class="x">,</span> <span class="x">:</span><span class="n">x_b2</span><span class="x">,</span> <span class="x">:</span><span class="n">x_W3</span><span class="x">,</span> <span class="x">:</span><span class="n">x_b3</span><span class="x">,</span> <span class="x">:</span><span class="n">y_W1</span><span class="x">,</span> <span class="x">:</span><span class="n">y_b1</span><span class="x">,</span> <span class="x">:</span><span class="n">y_W2</span><span class="x">,</span> <span class="x">:</span><span class="n">y_b2</span><span class="x">,</span> <span class="x">:</span><span class="n">y_W3</span><span class="x">,</span> <span class="x">:</span><span class="n">y_b3</span><span class="x">]</span>
        <span class="n">Gen</span><span class="o">.</span><span class="n">init_param!</span><span class="x">(</span><span class="n">custom_dest_proposal_neural</span><span class="x">,</span> <span class="n">name</span><span class="x">,</span> <span class="n">data</span><span class="x">[(:</span><span class="n">param</span><span class="x">,</span> <span class="n">name</span><span class="x">)])</span>
    <span class="k">end</span>
    <span class="n">data</span><span class="x">[:</span><span class="n">scores</span><span class="x">]</span>
<span class="k">end</span><span class="x">;</span>
</code></pre></div></div>

<p>We plot the estimate of the objective function over epochs:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot</span><span class="x">(</span><span class="n">scores</span><span class="x">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s">"Epochs"</span><span class="x">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s">"Estimate of expected conditional log probability density"</span><span class="x">,</span> 
    <span class="n">labelfontsize</span><span class="o">=</span><span class="mi">8</span><span class="x">,</span> <span class="n">label</span><span class="o">=</span><span class="n">nothing</span><span class="x">)</span>
</code></pre></div></div>

<p><img src="output_158_0.svg" alt="svg" /></p>

<p>Below, we visualize the trained proposal distribution for our data set:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">visualize_custom_destination_proposal</span><span class="x">(</span><span class="n">measurements</span><span class="x">,</span> <span class="n">start</span><span class="x">,</span> <span class="n">custom_dest_proposal_neural</span><span class="x">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="mi">1000</span><span class="x">)</span>
</code></pre></div></div>

<p><img src="output_160_0.png" alt="png" /></p>

<p>If we run inference with <code class="highlighter-rouge">amt_computation</code> set to 5, we see that the inferred distribution reflects the bias of the proposal:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">visualize_data_driven_inference</span><span class="x">(</span><span class="n">measurements</span><span class="x">,</span> <span class="n">scene</span><span class="x">,</span> <span class="n">start</span><span class="x">,</span> <span class="n">custom_dest_proposal_neural</span><span class="x">,</span>
    <span class="n">amt_computation</span><span class="o">=</span><span class="mi">5</span><span class="x">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">1000</span><span class="x">)</span>
</code></pre></div></div>

<p><img src="output_162_0.png" alt="png" /></p>

<p>As we increase the amount of computation, the effect of the proposal’s bias
is reduced:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">visualize_data_driven_inference</span><span class="x">(</span><span class="n">measurements</span><span class="x">,</span> <span class="n">scene</span><span class="x">,</span> <span class="n">start</span><span class="x">,</span> <span class="n">custom_dest_proposal_neural</span><span class="x">,</span>
    <span class="n">amt_computation</span><span class="o">=</span><span class="mi">50</span><span class="x">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">1000</span><span class="x">)</span>
</code></pre></div></div>

<p><img src="output_164_0.png" alt="png" /></p>

<p>This bias-correction is more noticeable the more computation we use (though here we only draw 100 approximate posterior samples):</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">visualize_data_driven_inference</span><span class="x">(</span><span class="n">measurements</span><span class="x">,</span> <span class="n">scene</span><span class="x">,</span> <span class="n">start</span><span class="x">,</span> <span class="n">custom_dest_proposal_neural</span><span class="x">,</span>
    <span class="n">amt_computation</span><span class="o">=</span><span class="mi">1000</span><span class="x">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">100</span><span class="x">)</span>
</code></pre></div></div>

<p><img src="output_166_0.png" alt="png" /></p>

<p>This example highlights an important aspect of importance sampling: it not
only <em>upweights</em> guesses that explain the data well; it also <em>downweights</em> guesses
that are too high-probability under the proposal distribution. That is, if a proposal
is heavily biased toward one region of the state space, all guesses in that region will
be downweighted accordingly. That’s why, even though (a) guesses in the left and right halves
of the room are equally likely, and (b) the
proposal stongly prefers the left half of the room, the importance sampling algorithm
samples roughly the same number of points in each half of the room.</p>

<p>In the limit of infinite computation, the distribution induced by importance sampling
converges to the true posterior, independent of the proposal. Indeed, using the
generic proposal with a high amount of computation produces very similar results:</p>

<div class="language-julia highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">visualize_inference</span><span class="x">(</span><span class="n">measurements</span><span class="x">,</span> <span class="n">scene</span><span class="x">,</span> <span class="n">start</span><span class="x">;</span> <span class="n">computation_amt</span><span class="o">=</span><span class="mi">1000</span><span class="x">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">100</span><span class="x">)</span>
</code></pre></div></div>

<p><img src="output_168_0.png" alt="png" /></p>


</div>

</main><!-- /.container -->

<!-- Footer -->
<footer class="page-footer font-small blue pt-4">

  <!-- Copyright -->
  <div class="footer-copyright text-center py-3">© 2020 Copyright: The author(s).
  </div>
  <!-- Copyright -->

</footer>
<!-- Footer -->

<script
			  src="https://code.jquery.com/jquery-3.5.1.min.js"
			  integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0="
			  crossorigin="anonymous"></script>
    <!--<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>-->
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js" integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha384-B4gt1jrGC7Jh4AgTPSdUtOBvfO8shuf57BaghqFfPlYxofvL8/KUEfYiJOMMV+rV" crossorigin="anonymous"></script>
  </body>
</html>
